[["index.html", "Housing prices Copenhagen Prerequisite Acknowledgements R session", " Housing prices Copenhagen Javier Elío, Henning S. Hansen, Frederik S. Hass, Carsten Keßler 2021-05-10 Prerequisite The data have been analysed with R (version 4.0.4) and Rstudio (version 1.4.1106), and the book has been created with bookdown package. The required packages are automatically checked and installed if needed from CRAN. # Create an auxiliary function for checking if a package is installed, # install it if it is not, and load the package # (based on https://gist.github.com/stevenworthington/3178163) ipak &lt;- function(pkg){ new_pkg &lt;- pkg[!(pkg %in% installed.packages()[, &quot;Package&quot;])] if (length(new_pkg)) install.packages(new_pkg, dependencies = TRUE, repos = &quot;http://cran.us.r-project.org&quot;) sapply(pkg, require, character.only = TRUE) } # List of packages pkg &lt;- c(&quot;bit64&quot;, &quot;bookdown&quot;, &quot;data.table&quot;, &quot;danstat&quot;, &quot;forcats&quot;, &quot;furrr&quot;, &quot;ggspatial&quot;, &quot;giscoR&quot;, &quot;gtsummary&quot;, &quot;janitor&quot;, &quot;kableExtra&quot;, &quot;knitr&quot;, &quot;latex2exp&quot;, &quot;mapview&quot;, &quot;osmextract&quot;, &quot;osrm&quot;, &quot;opentripplanner&quot;, &quot;patchwork&quot;, &quot;potential&quot;, &quot;rmarkdown&quot;, &quot;remotes&quot;, &quot;RColorBrewer&quot;, &quot;rappdirs&quot;, &quot;sf&quot;, &quot;stringr&quot;, &quot;SnowballC&quot;, &quot;stars&quot;, &quot;units&quot;, &quot;table1&quot;, &quot;tidyverse&quot;, &quot;tidytext&quot;, &quot;tm&quot;, &quot;tools&quot;) # Check and install ipak(pkg) Furthermore, we have created our own package for downloading kortforsyningen data to a local repository directly from R (i.e. dangeo). The package can be downloaded from GitHub: # Install package from GitHub if (!require(&quot;dangeo&quot;)) remotes::install_github(&quot;javiereliomedina/dangeo&quot;) library(dangeo) Although the kortforsyningen data are free, we would need to create a username and a password for getting access to them (you can make it here: Opret ny bruger). By default dangeo looks for credentials on .Renviron as: kortforsyningen_id = \"username\" and kortforsyningen_pwd = \"password\". You would need to save them with usethis::edit_r_environ(): # Set username and password # usethis::edit_r_environ() # Open .Renviron file, and save the username (kortforsyningen_id = &quot;your_username&quot;) and password (kortforsyningen_pwd = &quot;your_password&quot;) You would also need to define with dangeo_set_param() the local directory where the data are downloaded (loc_dir). It is defined as loc_dir = rappdirs::user_cache_dir(), although it can be changed loc_dir = ./your/local/path. The first time a file is downloaded with dangeo_get_data(), the process can be time consuming (there are some very big files). However, it will not be downloaded in subsequent calls if the files is already in the local directory (the dataset can be overwritten be setting overwrite = TRUE on dangeo_get_data()). Once we have our username and password, and we have define the local repository for the data, we can set them on our R-session: # Set local repository and password to kortforsyningen dangeo_set_param() Finally, the BBR data are storage in a OneDrive folder. You would need to have access to that folder, and save the path on .Renviron with usethis::edit_r_environ(). It has to be saved as OneDrive_BBR_path = \"your/OneDrive/BBR/path\". Acknowledgements This work has been financed by Aalborg University - AAU (Project: Global flows of migrants and their impact on north European welfare states - FLOW). The sole responsibility of this publication lies with the authors. AAU is not responsible for any use that may be made of the information contained therein. R session # R version 4.0.4 (2021-02-15) # Platform: x86_64-w64-mingw32/x64 (64-bit) # Running under: Windows 10 x64 (build 17763) # # Matrix products: default # # locale: # [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 # [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C # [5] LC_TIME=English_United Kingdom.1252 # # attached base packages: # [1] tools stats graphics grDevices utils datasets methods base # # other attached packages: # [1] dangeo_0.0.0.9000 tm_0.7-8 NLP_0.2-1 tidytext_0.3.0 # [5] dplyr_1.0.5 purrr_0.3.4 readr_1.4.0 tidyr_1.1.3 # [9] tibble_3.1.0 ggplot2_3.3.3 tidyverse_1.3.0 table1_1.3 # [13] units_0.7-1 stars_0.5-2 abind_1.4-5 SnowballC_0.7.0 # [17] stringr_1.4.0 sf_0.9-8 rappdirs_0.3.3 RColorBrewer_1.1-2 # [21] remotes_2.2.0 rmarkdown_2.7 potential_0.1.0 patchwork_1.1.1 # [25] osmextract_0.2.1 mapview_2.9.0 latex2exp_0.5.0 knitr_1.31 # [29] kableExtra_1.3.4 janitor_2.1.0 gtsummary_1.4.0 giscoR_0.2.2 # [33] ggspatial_1.1.5 furrr_0.2.2 future_1.21.0 forcats_0.5.1 # [37] danstat_0.1.0 data.table_1.14.0 bookdown_0.21 bit64_4.0.5 # [41] bit_4.0.4 # # loaded via a namespace (and not attached): # [1] leafem_0.1.3 colorspace_2.0-0 ellipsis_0.3.1 class_7.3-18 # [5] leaflet_2.0.4.1 snakecase_0.11.0 satellite_1.0.2 fs_1.5.0 # [9] base64enc_0.1-3 rstudioapi_0.13 proxy_0.4-25 listenv_0.8.0 # [13] fansi_0.4.2 lubridate_1.7.9.2 xml2_1.3.2 codetools_0.2-18 # [17] splines_4.0.4 Formula_1.2-4 jsonlite_1.7.2 gt_0.2.2 # [21] broom_0.7.6 dbplyr_2.1.0 png_0.1-7 compiler_4.0.4 # [25] httr_1.4.2 backports_1.2.1 assertthat_0.2.1 Matrix_1.3-2 # [29] cli_2.4.0 htmltools_0.5.1.1 gtable_0.3.0 glue_1.4.2 # [33] Rcpp_1.0.6 slam_0.1-48 cellranger_1.1.0 jquerylib_0.1.3 # [37] raster_3.4-5 vctrs_0.3.7 svglite_2.0.0 broom.helpers_1.3.0 # [41] crosstalk_1.1.1 lwgeom_0.2-5 xfun_0.22 globals_0.14.0 # [45] rvest_1.0.0 lifecycle_1.0.0 scales_1.1.1 hms_1.0.0 # [49] parallel_4.0.4 yaml_2.2.1 sass_0.3.1 stringi_1.5.3 # [53] tokenizers_0.2.1 e1071_1.7-6 rlang_0.4.10 pkgconfig_2.0.3 # [57] systemfonts_1.0.1 evaluate_0.14 lattice_0.20-41 htmlwidgets_1.5.3 # [61] tidyselect_1.1.0 parallelly_1.24.0 magrittr_2.0.1 R6_2.5.0 # [65] generics_0.1.0 DBI_1.1.1 withr_2.4.1 haven_2.3.1 # [69] pillar_1.6.0 survival_3.2-10 sp_1.4-5 janeaustenr_0.1.5 # [73] modelr_0.1.8 crayon_1.4.1 KernSmooth_2.23-18 utf8_1.2.1 # [77] readxl_1.3.1 grid_4.0.4 isoband_0.2.4 reprex_1.0.0 # [81] digest_0.6.27 classInt_0.4-3 webshot_0.5.2 stats4_4.0.4 # [85] munsell_0.5.0 viridisLite_0.4.0 bslib_0.2.4 "],["hedonic-price-model.html", "Chapter 1 Hedonic price model 1.1 House characteristics 1.2 Location characteristics 1.3 Neighbourhood characteristics", " Chapter 1 Hedonic price model House prices can be modelled based on the structural characteristics of the house (e.g. age, size, building materials, floor level, etc.), their location (e.g. proximity to urban services, distance to Central Business District - CBD, accessibility, etc.), and the surrounding environment (e.g. neighbourhood services and socio-economic aspects of its inhabitants, leisure facilities, noise levels, etc.) (Chen and Hao (2008), Gultekin and Yamamura (2006)). We will focus our study in the socio-economic aspects of the neighbourhood and, in particular, in the migration structure (e.g. migration pressure, ethnic groups, ). The house prices can be therefore defined by the following function (Chen and Hao (2008), Gultekin and Yamamura (2006)). \\[P_i = f(H_i, L_i, N_i) + \\epsilon \\] Where \\(f\\) represents the functional function in the hedonic model, P is the price of the house i, and \\(H_i\\), \\(L_i\\) and \\(N_i\\) are the vector of the structural characteristics, the location variables, and the neighbourhood characteristics of the house i, respectively. Finally, \\(\\epsilon\\) is the error term. 1.1 House characteristics We get the housing prices and the house properties from the Building and Dwelling Register (BBR). The dataset contains information about the building (e.g. building area, renovation year, etc.) and the residential unit (e.g. size, number of rooms, floor level, etc.). The data from residential units are unique for each dwelling, while some building characteristics are shared by several dwellings. We therefore merge both dataset for getting a dataset in which each row represents only one dwelling. There are data from 2006 to 2019. 1.2 Location characteristics OpenStreetMaps and kortforsyningen were used for getting the data about the urban services (e.g. public transport network, parks, ). Then, the interaction between those services and the house was modelled by potential models (Weber and Hirsch (2000), Gultekin and Yamamura (2006)), where the intensity of the interaction between the elements and the house is inversely proportional to the distance between them (Giraud and Commenges (2020)). \\[ p_i = \\sum_{j = i}^{n} M_i \\cdot f(d_{ij}) \\] Where \\(p_i\\) is the potential of the housing unit, \\(M_j\\) the mass of the service, and \\(f(d_{ij})\\) the negative function of the distance between the dwelling i and the service j. 1.3 Neighbourhood characteristics We have used the smallest administrative area of Denmark (i.e. parish) for evaluating the influence of the neighbourhoog characteristics on housing prices (Use also potential model here -&gt; e.g. locate the stock of migrant population on the centroid of each parish and get the interaction intensity in each house??). The following tables from the Denmark Statistics were used: SOGN10B: Disposable income for households by parish, price unit and income. SOGN05: Population (end November) by parish, socioeconomic status and sex SOGN07: Households disposal of vehicles by parish and use of cars (do you think it could be relevant? Do people think on parking issues when they buy a house?) KMSTA003: Summary vital statistics by parish and movements KMSTA001: Population 1. January by parish, ancestry and member of the National Church. VAN1AAR: Immigration (yearly) by municipality, sex, age, country of origin and citizenship Can we also have this dataset at parish level? "],["adm-units.html", "Chapter 2 Administrative units", " Chapter 2 Administrative units The Denmarks Administrative Geographical Division (DAGI) has been used for obtaining the administrative boundaries of Denmark. In this sense, the country is divided in approx. 2200 parishes, 98 municipalities, 5 regions, 22 judicial districts, 12 police districts, 92 constituencies and approx. 1100 postcodes. However, we focused our study in the Copenhagen (KOMKODE = 0101) and Frederiksberg (KOMKODE = 0147) communes. # Download DAGI (scale 1:10000) dangeo_get_data(ftp_folder = &quot;landinddelinger/dagi/SHAPE&quot;, zip_name = &quot;DAGIREF_SHAPE_UTM32-EUREF89.zip&quot;) # Codes of the communes under study (KOMKODE) study_area_codes &lt;- c(&quot;0101&quot;, &quot;0147&quot;) # Communes polygons of Denmark, and select those in the study area commune_link &lt;- paste(loc_dir, &quot;DAGIREF_SHAPE_UTM32-EUREF89/ADM&quot;, &quot;KOMMUNE.shp&quot;, sep = &quot;/&quot;) dk_commune &lt;- read_sf(commune_link) %&gt;% st_zm() %&gt;% st_transform(crs = &quot;EPSG:25832&quot;) dk_country &lt;- st_union(dk_commune) cph_commune &lt;- filter(dk_commune, KOMKODE %in% study_area_codes) # Parishes polygons of Denmark, and select those in the study area parish_link &lt;- paste(loc_dir, &quot;DAGIREF_SHAPE_UTM32-EUREF89/ADM&quot;, &quot;SOGN.shp&quot;, sep = &quot;/&quot;) dk_parish &lt;- read_sf(parish_link) %&gt;% st_zm() %&gt;% st_transform(crs = &quot;EPSG:25832&quot;) # Select those where the centroid is in the study area dk_parish_cent &lt;- st_centroid(dk_parish) cph_parish_cent &lt;- st_intersection(dk_parish_cent, cph_commune) cph_parish &lt;- filter(dk_parish, SOGNEKODE %in% cph_parish_cent$SOGNEKODE) %&gt;% # Combine several parish features geometries into one polygon group_by(SOGNEKODE, SOGNENAVN) %&gt;% summarise(geometry = st_union(geometry)) %&gt;% ungroup() %&gt;% # add area of the parish (in km2) mutate(prsh_area_km2 = as.numeric(units::set_units(st_area(.), km^2))) # Contour of the study area (merge the parishes in one polygon): study_area &lt;- cph_parish %&gt;% st_union() %&gt;% st_sf() %&gt;% st_transform(crs = &quot;EPSG:25832&quot;) # Plot parish ggplot() + geom_sf(data = cph_parish, fill = &quot;grey&quot;, color = &quot;grey50&quot;, size = 0.05) + my_theme_map() + annotation_scale(location = &quot;br&quot;, text_cex = 1) + annotation_north_arrow(location = &quot;br&quot;, pad_x = unit(1.6, &quot;cm&quot;), pad_y = unit(0.65, &quot;cm&quot;), which_north = &quot;true&quot;, height = unit(0.5, &quot;cm&quot;), width = unit(0.5, &quot;cm&quot;), style = north_arrow_orienteering(text_col = &quot;white&quot;, text_size = 1)) Figure 2.1: Parishes in the study area We have also created grid cells of 100m x 100m for aggregating some data at that scale (i.e. population density). # Make grids grids100m &lt;- study_area %&gt;% # Make regular grids (100m x 100m) st_make_grid(cellsize = 100) %&gt;% st_sf() %&gt;% # Select grids only in the study area mutate(int = st_intersects(., study_area) %&gt;% lengths &gt; 0) %&gt;% filter(int == TRUE) %&gt;% select(-int) %&gt;% # Name grids as &quot;g001&quot;, &quot;g002&quot;, ... mutate(grid_ID = paste0(&quot;g&quot;, stringr::str_pad(seq(1, nrow(.), 1), 3, pad = &quot;0&quot;))) # Points to estimate the potential (centroid of the grids of 100m x 100m) grids100m &lt;- grids100m %&gt;% # Nesting nest(data_poly = everything()) %&gt;% # add centroids of the grids mutate(data_points = map(data_poly, st_centroid)) # Plot ggplot() + geom_sf(data = cph_parish, fill = &quot;grey&quot;, color = &quot;grey50&quot;, size = 0.05) + geom_sf(data = grids100m$data_poly[[1]], fill = NA, color = &quot;red&quot;, size = 0.05) + my_theme_map() + annotation_scale(location = &quot;br&quot;, text_cex = 1) + annotation_north_arrow(location = &quot;br&quot;, pad_x = unit(1.6, &quot;cm&quot;), pad_y = unit(0.65, &quot;cm&quot;), which_north = &quot;true&quot;, height = unit(0.5, &quot;cm&quot;), width = unit(0.5, &quot;cm&quot;), style = north_arrow_orienteering(text_col = &quot;white&quot;, text_size = 1)) Figure 2.2: Grid cells of 100m x 100m There are therefore a total number of 65 parishes (Figure 2.1 and 1 grid cells (Figure 2.2) in the study area. The statistics for neighbourhood characteristics at parish level since they are the smallest administrative units in Denmark. "],["BBR-data.html", "Chapter 3 Housing data", " Chapter 3 Housing data We load all residences for year-round living (ENH_ANVEND_KODE) from the Building and Dwelling Register (BBR), we use this table for disaggregating population density from parish level to grid cells of 100m x 100m. 110 = Farmhouse for agricultural property. 120, 121, 122 = Detached single-family house (detached house). 130, 131, 132 = Townhouse, chain, or semi-detached house (vertical separation between the units). 140 = Multi-storey residential building (multi-family house, including two-family house (horizontal separation between the units). 150 = College. 160 = Residential building for residential institution. 190 = Second building for year-round living. # Buildings for year round living res_codes &lt;- tribble (~ENH_ANVEND_KODE, ~type, 110, &quot;Farmhouse&quot;, 120, &quot;Single-family house&quot;, 121, &quot;Single-family house&quot;, 122, &quot;Single-family house&quot;, 130, &quot;Semi-detached house&quot;, 131, &quot;Semi-detached house&quot;, 132, &quot;Semi-detached house&quot;, 140, &quot;Multi-storey&quot;, 150, &quot;College&quot;, 160, &quot;Residential institution&quot;, 190, &quot;Second building&quot;) %&gt;% # Convert type to factor mutate(type = factor(type)) %&gt;% # Convert to data.table as.data.table() # Function for reading residential units from a BBR files (.csv): # Get only residential units in the study area # @param .file Path to OneDrive with the data (.csv format) # @param .area Area where we would get the data (default = study_area) f_res_units &lt;- function(.file, .area = study_area) { # Select only Residential houses - Buildings for year-round living dt &lt;- fread(.file)[ENH_ANVEND_KODE %in% res_codes$ENH_ANVEND_KODE] # Input empty cells (buildings with only one floor) in Etagebetegn as &quot;st&quot; dt[, Etagebetegn := fifelse(Etagebetegn == &quot;&quot;, &quot;st&quot;, Etagebetegn)] # Etagebetegn as ordered factor dt[, Etagebetegn := factor(Etagebetegn, c(&quot;k2&quot;, &quot;kl&quot;, &quot;st&quot;, seq(1, 36, 1)), ordered = TRUE)] # Group floor levels with 5 or more dt[, floor_level := fct_other(Etagebetegn, drop = factor(seq(5, 36)), other_level = &quot;5 or more&quot;)] # Add residential description (type) into the dataset dt &lt;- merge(dt, res_codes, by = &quot;ENH_ANVEND_KODE&quot;) # Add year of the BBR dataset dt[ , BBR_year := parse_number(stringr::str_extract(.file, &quot;_[0-9]+_&quot;))] # Convert columns with codes (*_KODE) to character cols &lt;- grep(&quot;_KODE&quot;, names(dt)) dt[ , (cols) := lapply(.SD, as.character), .SDcols = cols] # Convert to sf objects and get only points in the study area dt &lt;- dt %&gt;% st_as_sf(coords = c(&quot;etrs89koordinat_ost&quot;, &quot;etrs89koordinat_nord&quot;), crs = &quot;EPSG:25832&quot;) %&gt;% # Points in the study area mutate(int = st_intersects(., .area) %&gt;% lengths &gt; 0) %&gt;% filter(int == TRUE) } # Load all csv files (one file for each year) in the same table with a column indicating the year of the dataset: # Load residential units # NOTE: you may need to change the path to OneDrive - Aalborg Universitet # Read all the data together csv_files_path &lt;- list.files(path = Sys.getenv(&quot;OneDrive_BBR_path&quot;), pattern = &quot;*.csv&quot;, full.names = TRUE) plan(multisession, workers = 7) res_units &lt;- future_map_dfr(.x = csv_files_path, .f = f_res_units) plan(&quot;default&quot;) However, for housing prices we focus our analysis to the main building types in the City of Copenhagen (Figure 3.1), which are in this order: i) multi-storey residential buildings (code 140), ii) detached single-family houses (codes 120, 121, 122), iii) colleges (code 150), and iv) semi-detached houses (codes 130, 131, 132). # Aux. function for plotting 2D kernel density maps: f &lt;- function(.data) { .data %&gt;% st_coordinates() %&gt;% as_tibble() %&gt;% ggplot() + geom_sf(data = cph_parish, fill = &quot;grey&quot;, color = &quot;grey50&quot;, size = 0.05) + geom_point(aes(X, Y), size = 0.02, shape = 16) + stat_density_2d(aes(X, Y, fill = ..level..), alpha = 0.5, h = 700, geom = &quot;polygon&quot;) + scale_fill_distiller(palette = &quot;Spectral&quot;) + theme_void() + theme(legend.position = &quot;none&quot;) + labs(title = .data$type, x = &quot;&quot;, y = &quot;&quot;) } # Plots p &lt;- res_units %&gt;% filter(BBR_year == 2019) %&gt;% # Reorder type factors by the frequency they appear mutate(type = fct_infreq(type)) %&gt;% # Split by house type group_split(type) %&gt;% map( ~ f(.)) wrap_plots(p) + annotation_scale(location = &quot;br&quot;, text_cex = 1) + annotation_north_arrow(location = &quot;br&quot;, pad_x = unit(0.70, &quot;cm&quot;), pad_y = unit(0.65, &quot;cm&quot;), which_north = &quot;true&quot;, height = unit(0.5, &quot;cm&quot;), width = unit(0.5, &quot;cm&quot;), style = north_arrow_orienteering(text_col = &quot;white&quot;, text_size = 1)) + plot_annotation(title = &quot;Residential units in 2019&quot;, theme = theme(plot.title = element_text(size = 14, colour = &quot;darkblue&quot;, face = &quot;bold&quot;), plot.caption = element_text(size = 9, colour = &quot;grey25&quot;) ) ) Figure 3.1: 2D kernel density map Then, we selected from the main residential buildings those that are on the ordinary free trade (OVERDRAGELSES_KODE == 1 - Almindelig frit salg) or public sales (OVERDRAGELSES_KODE == 3 - Auktion). Finally, we filtered those dwellings that are actually used for residential purpose (i.e. BOLIGTYPE_KODE \\(\\neq\\) E - Andet (bl.a. institutioner og erhverv) or BOLIGTYPE_KODE \\(\\neq\\) 5 - Sommer-/fritidsbolig). Dwelling with a size lower that 10 \\(m^2\\) were removed from the analysis. Colleges were also excluded from the data analysis since they are a special type of buildings dedicated to students residences mainly outside of the free marked. selected_res_units &lt;- c(&quot;Multi-storey&quot;, &quot;Single-family house&quot;, &quot;Semi-detached house&quot;) res_units_oft &lt;- res_units %&gt;% # Convert to tibble as_tibble() %&gt;% # Select main residential units in the area filter(type %in% selected_res_units) %&gt;% # ordinary free trade or auction filter(OVERDRAGELSES_KODE == &quot;1&quot; | OVERDRAGELSES_KODE == &quot;3&quot;) %&gt;% # Remove BOLIGTYPE_KODE = E or 5 form the dataset filter(BOLIGTYPE_KODE != &quot;E&quot; | BOLIGTYPE_KODE != &quot;5&quot;) %&gt;% # Remove tiny dwellings (area &lt; 10 m2) filter(BEBO_ARL &gt;= 10) %&gt;% # Drop unused factors levels droplevels() Finally, we adjusted the housing prices to 2019 prices. In this regard, we take into account the inflation and, therefore, prices from different years can be compared (Valtersdorf Møller (2020)). The adjusted price is obtained as follow: \\[ Pice_{2019} = Price_{i} \\cdot \\frac{Index_{2019}}{Index_{i}}\\] Where, \\(Price_{2019}\\) is the adjusted housing price for 2019, \\(Price_{i}\\) is the price of the respective year \\(i\\), and \\(Index_{i}\\) and \\(Index_{2019}\\) are the price indexes for the origin year \\({i}\\) and \\(2019\\), respectively. The indexes have been obtained from Statistic Denmark; i.e. table EJ66: Price index for sales property (2006=100) by region, category of real property and unit, and targeted for the study area; i.e. Province Byen København - Copenhagen City (Table 3.1). Inconsistent values have been removed; i.e. 2019 adjusted prices &lt; 10 kDKK (approx. 1300). # DST table (EJ66: Price index for sales property (2006=100) by region, category of real property and unit) id_table &lt;- &quot;EJ66&quot; dat_meta &lt;- get_table_metadata(table_id = id_table, variables_only = TRUE) # Values to retrieve variables &lt;- list( # Province Byen København: region = 01 list(code = &quot;OMRÅDE&quot;, values = &quot;01&quot;), # Category of real property list(code = &quot;EJENDOMSKATE&quot;, values = c(&quot;0111&quot;, &quot;2103&quot;)), # Index list(code = &quot;TAL&quot;, values = NA), # From 2004 to 2019 list(code = &quot;Tid&quot;, values = seq(2004, 2019, 1)) ) # Get index price_index &lt;- get_data(&quot;EJ66&quot;, variables) %&gt;% # Get index filter(TAL == &quot;Index&quot;) %&gt;% # Translate into English rename(region = OMRÅDE, category = EJENDOMSKATE, unit = TAL, date = TID, index = INDHOLD) %&gt;% # Convert index tu numeric mutate(index = as.numeric(index)) %&gt;% # Remove region and unit columns select(-region, -unit) # Print price index table price_index %&gt;% # Wide format pivot_wider(names_from = date, values_from = index) %&gt;% kbl(caption = &quot;Price index for sale properties in Copenhagen City&quot;) %&gt;% kable_paper() %&gt;% scroll_box(width = &quot;100%&quot;) Table 3.1: Price index for sale properties in Copenhagen City category 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 One-family houses 60.9 79.4 100 96.1 89.7 74.7 80.9 81.5 79.5 85.7 93.3 102 109 115 123 125 Owner-occupied flats, total 60.2 79.4 100 91.8 82.2 71.2 77.7 79.1 80.6 89.4 99.2 112 122 132 139 138 # Adjust housing prices price_index_2019 &lt;- filter(price_index, date == 2019) %&gt;% rename(index_2019 = index) res_units_oft &lt;- res_units_oft %&gt;% # Column with price index categories mutate(category = case_when( type == &quot;Single-family house&quot; ~ &quot;One-family houses&quot;, TRUE ~ &quot;Owner-occupied flats, total&quot;)) %&gt;% # Add price index by year and category left_join(price_index, by = c(&quot;category&quot; = &quot;category&quot;, &quot;BBR_year&quot; = &quot;date&quot;)) %&gt;% # Add price index in 2019 by category left_join(price_index_2019, by = c(&quot;category&quot; = &quot;category&quot;)) %&gt;% # Calculate prices 2019 mutate(price2019_kDKK = (KONTANT_KOEBESUM * index_2019 / index) / 1000) %&gt;% # Remove prices &lt; 10 kDKK filter(price2019_kDKK &gt;= 10) The housing price per square meter (\\(kDDK/m^2\\)) is calculated by dividing the 2019 adjusted prices by the dwelling size (BEBO_ARL). res_units_oft &lt;- res_units_oft %&gt;% # Price per m2 mutate(price2019_kDKK_m2 = price2019_kDKK / BEBO_ARL) The total number of residential units used for the analysis is 196451 (Table 3.2). # Table with Number of residential units res_units_oft %&gt;% # Summarize by type or residency and year group_by(type, BBR_year) %&gt;% summarise(n = n()) %&gt;% ungroup() %&gt;% # Arrange and add row with totals arrange(BBR_year, desc(n)) %&gt;% # Pivot pivot_wider(names_from = BBR_year, values_from = n) %&gt;% adorn_totals(&quot;row&quot;) %&gt;% kbl(caption = &quot;Number of residential dwellings in the free trade by year&quot;) %&gt;% kable_paper() %&gt;% row_spec(4, bold = TRUE) %&gt;% scroll_box(width = &quot;100%&quot;) Table 3.2: Number of residential dwellings in the free trade by year type 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 Multi-storey 12076 14105 13734 12203 7084 5171 14716 8193 9189 9910 11483 12806 11322 11939 11453 11783 Single-family house 667 669 550 563 464 433 794 552 899 661 698 704 713 707 665 719 Semi-detached house 268 288 280 355 256 203 313 478 457 483 515 527 1347 1254 1260 542 Total 13011 15062 14564 13121 7804 5807 15823 9223 10545 11054 12696 14037 13382 13900 13378 13044 The summary descriptive statistics of the housing prices are: # Table theme theme_gtsummary_compact() # Create variable labels of the variables to be printed in the table labelled::var_label(res_units_oft$price2019_kDKK) &lt;- &quot;Adjusted prices (kDKK)&quot; labelled::var_label(res_units_oft$BEBO_ARL) &lt;- &quot;Dwelling size (m2)&quot; labelled::var_label(res_units_oft$price2019_kDKK_m2) &lt;- &quot;Adjusted prices per square meter (kDKK/m2)&quot; # Summary table res_units_oft %&gt;% # Select variables of interest select(type, price2019_kDKK, BEBO_ARL, price2019_kDKK_m2) %&gt;% # Summary values tbl_summary(by = type, type = all_continuous() ~ &quot;continuous2&quot;, statistic = all_continuous() ~ c(&quot;{mean}&quot;, &quot;{median}&quot;, &quot;{p25} - {p75}&quot;, &quot;{min} - {max}&quot;), missing = &quot;no&quot;) %&gt;% add_overall() %&gt;% modify_spanning_header(c(&quot;stat_1&quot;, &quot;stat_2&quot;, &quot;stat_3&quot;) ~ &quot;**House type**&quot;) %&gt;% modify_footnote(update = everything() ~ NA) %&gt;% bold_labels() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #mwlefoodfi .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: small; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #mwlefoodfi .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mwlefoodfi .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #mwlefoodfi .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #mwlefoodfi .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mwlefoodfi .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mwlefoodfi .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #mwlefoodfi .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #mwlefoodfi .gt_column_spanner_outer:first-child { padding-left: 0; } #mwlefoodfi .gt_column_spanner_outer:last-child { padding-right: 0; } #mwlefoodfi .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #mwlefoodfi .gt_group_heading { padding: 1px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #mwlefoodfi .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #mwlefoodfi .gt_from_md > :first-child { margin-top: 0; } #mwlefoodfi .gt_from_md > :last-child { margin-bottom: 0; } #mwlefoodfi .gt_row { padding-top: 1px; padding-bottom: 1px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #mwlefoodfi .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #mwlefoodfi .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 1px; padding-bottom: 1px; padding-left: 5px; padding-right: 5px; } #mwlefoodfi .gt_first_summary_row { padding-top: 1px; padding-bottom: 1px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #mwlefoodfi .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 1px; padding-bottom: 1px; padding-left: 5px; padding-right: 5px; } #mwlefoodfi .gt_first_grand_summary_row { padding-top: 1px; padding-bottom: 1px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #mwlefoodfi .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #mwlefoodfi .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mwlefoodfi .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mwlefoodfi .gt_footnote { margin: 0px; font-size: 90%; padding: 1px; } #mwlefoodfi .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mwlefoodfi .gt_sourcenote { font-size: 90%; padding: 1px; } #mwlefoodfi .gt_left { text-align: left; } #mwlefoodfi .gt_center { text-align: center; } #mwlefoodfi .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #mwlefoodfi .gt_font_normal { font-weight: normal; } #mwlefoodfi .gt_font_bold { font-weight: bold; } #mwlefoodfi .gt_font_italic { font-style: italic; } #mwlefoodfi .gt_super { font-size: 65%; } #mwlefoodfi .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Characteristic Overall, N = 196,451 House type Multi-storey, N = 177,167 Semi-detached house, N = 8,826 Single-family house, N = 10,458 Adjusted prices (kDKK) Mean 47,735 51,961 9,901 8,067 Median 4,420 4,297 5,057 4,960 IQR 2,701 - 15,995 2,593 - 22,343 3,842 - 6,937 3,869 - 6,396 Range 11 - 1,778,677 11 - 1,778,677 30 - 261,346 25 - 291,062 Dwelling size (m2) Mean 89 84 131 137 Median 81 77 130 128 IQR 60 - 108 58 - 101 115 - 142 103 - 158 Range 10 - 733 10 - 655 12 - 402 10 - 733 Adjusted prices per square meter (kDKK/m2) Mean 665 728 83 100 Median 46 47 42 40 IQR 36 - 195 37 - 276 31 - 53 32 - 48 Range 0 - 37,056 0 - 37,056 0 - 15,876 0 - 17,500 "],["pop-DST.html", "Chapter 4 Population data 4.1 Population density", " Chapter 4 Population data Population data at parish level have been retrieved from Statistics Denmark using the R-package danstat. We have created two auxiliary function for reading the data. steps loops by year for getting small pieces of information from the DST API and then putting all together in a data frame. In this sense, we overcome the limitation of the number of rows we can retrieve from the API (i.e. if we call a large dataset we get the error: Error: API did not return text/csv). Then, rm_words is used in the cleaning process for simplifying the description of some variables we would like to use as columns names. # Loop by year for getting DST data steps &lt;- function(year){ var_values &lt;- list(id_region, id_ancestry, year) var_input &lt;- purrr::map2(.x = var_codes, .y = var_values, .f = ~list(code = .x, values = .y)) get_data(id_table, variables = var_input) } # Remove punctuation, lowercase, stem, stopwords, and collapse strings rm_words &lt;- function(x, stopwords) { x %&gt;% strsplit(&quot; &quot;, fixed = TRUE) %&gt;% lapply(tm::removePunctuation) %&gt;% lapply(tolower) %&gt;% lapply(SnowballC::wordStem) %&gt;% lapply(function(x) x[!x %in% stopwords]) %&gt;% vapply(function(x) paste(x , collapse = &quot;_&quot;), character(1)) } We have loaded the following tables: KMSTA001: Population 1. January by parish, ancestry and National Church id_table &lt;- &quot;KMSTA001&quot; var_pop &lt;- get_table_metadata(table_id = id_table, variables_only = TRUE) # Codes for var_input var_codes &lt;- c(&quot;SOGN&quot;, &quot;HERKOMST&quot;, &quot;Tid&quot;) # Values for var_input # Region: parishes of the study area (i.e. cph_parish) id_region &lt;- cph_parish$SOGNEKODE # Ancestry id_ancestry &lt;- NA # Quarters id_year &lt;- var_pop$values[[4]]$id # Select all years # Read data prsh_ances_dst &lt;- id_year %&gt;% future_map(steps) %&gt;% bind_rows() plan(&quot;default&quot;) # Clean data prsh_ances &lt;- prsh_ances_dst %&gt;% # Translate column names into English rename(parish = SOGN, ancestry = HERKOMST, date = TID, value = INDHOLD) %&gt;% # Get parish codes (first number of the string) mutate(prsh_id = stringr::str_extract(parish, &quot;[[:alnum:]]*&quot;)) %&gt;% # Remove the code from the string (prsh) mutate(parish = sub(&quot;[[:alnum:]]* &quot;, &quot;&quot;, parish)) %&gt;% # Get municipality (info inside the parenthesis) mutate(prsh_muni = stringr::str_extract(parish, &quot;(?&lt;=\\\\().*(?=\\\\))&quot;), prsh_muni = gsub(&quot; Municipality&quot;, &quot;&quot;, prsh_muni), # removes white space from start and end of string prsh_muni = stringr::str_trim(prsh_muni)) %&gt;% # Get parish name (outside parenthesis) mutate(prsh_name = stringr::str_extract(parish, &quot;(.*(?=\\\\())&quot;), prsh_name = stringr::str_trim(prsh_name)) %&gt;% # Remove duplicate info and order columns select(prsh_id, prsh_name, prsh_muni, date, ancestry, value) %&gt;% # Make shorter names in ancestry mutate(ancestry = case_when( ancestry == &quot;Persons of Danish origin&quot; ~ &quot;pop_dan&quot;, ancestry == &quot;Immigrants from western countries&quot; ~ &quot;pop_mi_wst&quot;, ancestry == &quot;Immigrants from non-western countries&quot; ~ &quot;pop_mi_nwst&quot;, ancestry == &quot;Descendants from western countries&quot; ~ &quot;pop_de_wst&quot;, ancestry == &quot;Descendants from non-western countries&quot; ~ &quot;pop_de_nwst&quot;), ancestry = factor(ancestry)) %&gt;% # Pivot (one row for peach parish and year) pivot_wider(names_from = ancestry, values_from = value) %&gt;% # Merge immigrants and their descendants (i.e. foreigners) mutate(pop_frgn_wst = pop_mi_wst + pop_de_wst, pop_frgn_nwst = pop_mi_nwst + pop_de_nwst) %&gt;% select(-c(pop_mi_wst, pop_de_wst, pop_mi_nwst, pop_de_nwst)) %&gt;% # Add column with total population mutate(pop_total = select(., starts_with(&quot;pop_&quot;)) %&gt;% rowSums()) KMSTA003: Summary vital statistics by parish and movements id_table &lt;- &quot;KMSTA003&quot; var_pop &lt;- get_table_metadata(table_id = id_table, variables_only = TRUE) # Codes for var_input var_codes &lt;- c(&quot;SOGN&quot;, &quot;KIRKEBEV&quot;, &quot;Tid&quot;) # Values for var_input # Region: all parish id_region &lt;- cph_parish$SOGNEKODE # Ancestry id_movements &lt;- NA # Quarters id_year &lt;- var_pop$values[[3]]$id # Select all years # Read data plan(multisession) prsh_stats_dst &lt;- id_year %&gt;% future_map(steps) %&gt;% bind_rows() plan(&quot;default&quot;) # Clean data prsh_stats &lt;- prsh_stats_dst %&gt;% # Translate column names into English rename(parish = SOGN, movements = KIRKEBEV, date = TID, value = INDHOLD) %&gt;% # Get parish codes (first number of the string) mutate(prsh_id = stringr::str_extract(parish, &quot;[[:alnum:]]*&quot;)) %&gt;% # Remove the code from the string (prsh) mutate(parish = sub(&quot;[[:alnum:]]* &quot;, &quot;&quot;, parish)) %&gt;% # Get municipality (info inside the parenthesis) mutate(prsh_muni = stringr::str_extract(parish, &quot;(?&lt;=\\\\().*(?=\\\\))&quot;), prsh_muni = gsub(&quot; Municipality&quot;, &quot;&quot;, prsh_muni), # removes white space from start and end of string prsh_muni = stringr::str_trim(prsh_muni)) %&gt;% # Get parish name (outside parenthesis) mutate(prsh_name = stringr::str_extract(parish, &quot;(.*(?=\\\\())&quot;), prsh_name = stringr::str_trim(prsh_name)) %&gt;% # remove duplicate info and order columns select(prsh_id, prsh_name, prsh_muni, date, movements, value) %&gt;% # Clean arguments in movements (remove punctuation, stop-words, stem, and collapse) mutate(movements = rm_words(movements, c(&quot;in&quot;, &quot;the&quot;, &quot;of&quot;))) %&gt;% # Pivot (one row for each parish and year) pivot_wider(names_from = movements, values_from = value) One we have the data we merge both dataset and add the spatial information (note that there are only summary statistics from 2015): # Merge both tables in one: prsh_pop &lt;- prsh_ances %&gt;% full_join(prsh_stats) %&gt;% # remove rows with no summary data (summary data only from 2015 to 2020) filter(date &gt;= 2015, date &lt;= 2020) # Add the spatial information: prsh_pop_sf &lt;- cph_parish %&gt;% rename(prsh_id = SOGNEKODE) %&gt;% select(prsh_id, prsh_area_km2) %&gt;% left_join(prsh_pop, by = c(&quot;prsh_id&quot;)) 4.1 Population density We disaggregate the population data at Parish level to grid cells of 100m x 100m using residential buildings as ancillary data. BBR data represent the situation at the beginning of the given year. Therefore, when we link the BBR data with the population data, which also represent the situation at the first day of the year, we use the population of the same year (e.g. BBR data from 2019 and population data from 2019). 4.1.1 Choropleth by ancestry Plot population density at the last day of 2019 (first of 2010) by parish and ancestry (figure 4.1). col &lt;- brewer.pal(9, &quot;YlGnBu&quot;) pal &lt;- colorRampPalette(col) my_pallette &lt;- pal(10) pop_dens_choropleth &lt;- prsh_pop_sf %&gt;% select(prsh_id, prsh_name, prsh_area_km2, date, pop_total, pop_dan, pop_frgn_wst, pop_frgn_nwst) %&gt;% filter(date == 2019) %&gt;% # Calulate population density (pop/area) mutate(across(starts_with(&quot;pop_&quot;), ~ . / (1000 * prsh_area_km2))) %&gt;% rename_with(~paste(.x, &quot;km2&quot;, sep = &quot;_&quot;), starts_with(&quot;pop&quot;)) %&gt;% as_tibble() %&gt;% pivot_longer(starts_with(&quot;pop_&quot;)) %&gt;% st_as_sf() %&gt;% mutate(name = factor(name, levels = c(&quot;pop_total_km2&quot;, &quot;pop_dan_km2&quot;, &quot;pop_frgn_wst_km2&quot;, &quot;pop_frgn_nwst_km2&quot;), labels = c(&quot;Total&quot;, &quot;Danish origin&quot;, &quot;Immigrants and their descendants from western countries&quot;, &quot;Immigrants and their descendants from non-western countries&quot;))) brks_c &lt;- c(min(pop_dens_choropleth$value), 1, 2, 4, 8, 12, 16, 20, 25, 30, ceiling(max(pop_dens_choropleth$value))) pop_dens_choropleth %&gt;% ggplot() + geom_sf(aes(fill = cut(value, breaks = brks_c, include.lowest = T)), color = &quot;grey50&quot;, size = 0.05) + scale_fill_manual(name = TeX(&quot;$\\\\overset{\\\\textbf{Population}}{(x1000/km^2)}$&quot;), values = my_pallette, drop = FALSE, guide = guide_legend(reverse=TRUE)) + my_theme_map() + theme(plot.title = element_text(size = 12, colour = &quot;darkblue&quot;, face = &quot;bold&quot;), strip.text = element_text(size = 9, color = &quot;black&quot;, face = &quot;italic&quot;)) + labs(x = &quot;&quot;, y = &quot;&quot;) + facet_wrap( ~ name) Figure 4.1: Population density at the first day of 2019 by parishes (choropleth) 4.1.2 Disaggregating population data The procedure is as follow: We calculate the occupancy rate (OR) for the residential units of each parish (j): \\[OR_{j} = \\frac{pop_{j}}{N_{j}}\\] We make grid cells of 100m x 100m over the study area We select only the grids with residential units Detect to what parish (j) belong each grid (i). (Note that one grids may be in more that one parish) Calculate the number of dwellings per grid and parish (\\(N_{ij}\\)) Estimate the population in each grid (i) base the occupancy rate by parish (j): \\[pop_{gi} = \\sum_{j = 1}^{n}(OR_{j} \\cdot N_{ij})\\] Population density: \\[PD_{i} = \\frac{pop_{i}}{A_{i}}\\] We have created the following function for the analysis: #&#39; Calculate the population density in the grids created by f_grids #&#39; @param .pop POLYGONS with the population data (i.e. prsh_pop_sf) #&#39; @param .parish POLYGONS where the number of units will be calculated #&#39; @param .res_points POINTS with the residential units (e.g. res_units) #&#39; @param .grids Grid cells generated by f_grids #&#39; @param .year Year of the analysis f_pd_grids &lt;- function(.pop, .parish, .res_points, .grids, .year) { # Population at the last day of the year (.year) pop_year &lt;- .pop %&gt;% # Select population data at the first day of the quarter select(prsh_id, prsh_name, prsh_area_km2, date, pop_total, pop_dan, pop_frgn_wst, pop_frgn_nwst) %&gt;% # select the data at the end of the year (first dat of the next year) filter(date == (.year)) # BBR of the selected year (represent the last day of the year) BBR_year &lt;- filter(.res_points, BBR_year == .year) # Calculate occupancy rate (&quot;OR&quot;) of the residential units in each parish in a year OR &lt;- pop_year %&gt;% # number of units per parish mutate(n_units = st_intersects(., BBR_year, dist = 10) %&gt;% map(., ~length(.)) %&gt;% unlist()) %&gt;% # mean population per unit in each parish mutate(across(starts_with(&quot;pop&quot;), ~ . / n_units)) %&gt;% rename_with(~paste(.x, &quot;or&quot;, sep = &quot;_&quot;), starts_with(&quot;pop&quot;)) %&gt;% # output as table as_tibble() %&gt;% select(-n_units, -geometry) # Get only the grids with residential units on them gru &lt;- .grids %&gt;% # Number of residential units per grid mutate(n_units = st_intersects(., BBR_year , dist = 10) %&gt;% map(., ~length(.)) %&gt;% unlist()) %&gt;% # Get grids with residential buildings filter(n_units &gt; 0) %&gt;% # Detect to what parish belong the grid st_intersection(., .parish ) %&gt;% # Remove parish area select(-prsh_area_km2, -SOGNENAVN) %&gt;% # convert to table as_tibble() # Population density by grids gru %&gt;% # Merge OR per parish left_join(OR, by = c(&quot;SOGNEKODE&quot; = &quot;prsh_id&quot;)) %&gt;% st_sf() %&gt;% # recalculate population by grid mutate(across(starts_with(&quot;pop&quot;), ~ . * n_units)) %&gt;% rename_with(~gsub(&quot;_or&quot;, &quot;&quot;, .), .col = starts_with(&quot;pop&quot;)) %&gt;% # sum population of each parish of the grid group_by(grid_ID) %&gt;% summarise(pop_total = sum(pop_total), pop_dan = sum(pop_dan), pop_frgn_wst = sum(pop_frgn_wst), pop_frgn_nwst = sum(pop_frgn_nwst), n_units = sum(n_units)) %&gt;% ungroup() %&gt;% # Area of the grid mutate(area_km2 = as.numeric(units::set_units(st_area(.), km^2))) %&gt;% # Population density (pop/area) mutate(across(starts_with(&quot;pop_&quot;), ~ . / (1000 * area_km2))) %&gt;% rename_with(~paste(.x, &quot;km2&quot;, sep = &quot;_&quot;), starts_with(&quot;pop&quot;)) %&gt;% # Pivot longer as_tibble() %&gt;% pivot_longer(starts_with(&quot;pop_&quot;)) %&gt;% st_as_sf() %&gt;% # Remove polygons with 0 population filter(value &gt; 0) } We can therefore estimate the population in a specific year (e.g. 2019) at the first day of the year by grid cells of 100m x 100m and ancestry (figure 4.2). pop_2019_g100m &lt;- f_pd_grids(.pop = prsh_pop_sf, .parish = cph_parish, .res_points = res_units, .grids = grids100m$data_poly[[1]], .year = 2019) brks &lt;- c(min(pop_2019_g100m$value), 1, 2, 4, 8, 12, 16, 20, 25, 30, ceiling(max(pop_2019_g100m$value))) pop_2019_g100m %&gt;% mutate(name = factor(name, levels = c(&quot;pop_total_km2&quot;, &quot;pop_dan_km2&quot;, &quot;pop_frgn_wst_km2&quot;, &quot;pop_frgn_nwst_km2&quot;), labels = c(&quot;Total&quot;, &quot;Danish origin&quot;, &quot;Immigrants and their descendants from western countries&quot;, &quot;Immigrants and their descendants from non-western countries&quot;))) %&gt;% ggplot() + geom_sf(data = cph_parish, fill = &quot;grey&quot;, color = &quot;grey50&quot;, size = 0.05) + geom_sf(aes(fill = cut(value, breaks = brks, include.lowest = T)), color = NA) + scale_fill_manual(name = TeX(&quot;$\\\\overset{\\\\textbf{Population}}{(x1000/km^2)}$&quot;), values = my_pallette, drop = FALSE, guide = guide_legend(reverse = TRUE)) + my_theme_map() + theme(plot.title = element_text(size = 12, colour = &quot;darkblue&quot;, face = &quot;bold&quot;), strip.text = element_text(size = 9, color = &quot;black&quot;, face = &quot;italic&quot;)) + labs(x = &quot;&quot;, y = &quot;&quot;) + facet_wrap( ~ name) Figure 4.2: Population density at the first day of 2019 by grid cells of 100m x 100m 4.1.3 Population density WorldPop We compare our results with the WorldPop total population estimation per grid-cell of 3 arc (approx. gri cells of 100m x 100m; Figure 4.3), and the spatial pattern is similar between both maps although our approach seems more precise since it takes into account the population data at parish level from Statistic Denmark. dnk_ppp_2019_link &lt;- &quot;https://data.worldpop.org/GIS/Population/Global_2000_2020/2019/DNK/dnk_ppp_2019.tif&quot; # Download data into the local repository (i.e. loc_dir) download.file(url = dnk_ppp_2019_link, destfile = paste(loc_dir, &quot;dnk_ppp_2019.tif&quot;, sep = &quot;/&quot;), method = &quot;curl&quot;) # Load file dnk_ppp_2019 &lt;- read_stars(.x = paste(loc_dir, &quot;dnk_ppp_2019.tif&quot;, sep = &quot;/&quot;), proxy = TRUE) # Crop study area bbox &lt;- study_area %&gt;% st_transform(crs = st_crs(dnk_ppp_2019)) cph_ppp_2019 &lt;- st_crop(dnk_ppp_2019, bbox) %&gt;% st_transform(crs = &quot;EPSG:25832&quot;) # Plot col &lt;- brewer.pal(9, &quot;YlGnBu&quot;) pal &lt;- colorRampPalette(col) my_pallette &lt;- pal(10) brks &lt;- c(min(cph_ppp_2019$dnk_ppp_2019.tif, na.rm = TRUE), 1, 2, 4, 8, 12, 16, 20, 25, 30, max(cph_ppp_2019$dnk_ppp_2019.tif, na.rm = TRUE)) cph_ppp_2019 &lt;- cph_ppp_2019 %&gt;% mutate( pop_cuts = cut(dnk_ppp_2019.tif, breaks = brks, include.lowest = T)) ggplot() + geom_sf(data = cph_parish, fill = &quot;grey&quot;, color = &quot;grey50&quot;, size = 0.05) + geom_stars(data = cph_ppp_2019, aes(fill = pop_cuts)) + scale_fill_manual(name = TeX(&quot;$\\\\overset{\\\\textbf{Population}}{(x1000/km^2)}$&quot;), values = my_pallette, drop = FALSE, guide = guide_legend(reverse=TRUE)) + labs(title = &quot;Estimated total number of people per grid-cell of 3 arc&quot;, caption = &quot;Source: WorlpPop (https://data.worldpop.org)&quot;) + my_theme_map() Figure 4.3: WorldPop total population density estimations in 2019 "],["OSM-features.html", "Chapter 5 Open Street Map 5.1 Features 5.2 Potential model", " Chapter 5 Open Street Map The location information has been obtained from Open Street Map. We have selected services inside a buffer of approx. 2 km around the study area (Figure 5.1 and 5.2), assuming that people may use then (e.g. parks, parking areas) outside Copenhagen City but they are close enough to people houses. Then, we estimate the accessibility to each services (i.e. feature) in the centroid of the grid cell of 100m x 100m; i.e. Potential model chapter 1. We selected two types of features; i. areal features and ii. point features; where the mass of the service (\\(M_j\\)) is the area of the polygon in \\(m^2\\) or equal for all services (i.e. 1), respectively. On the other hand, the distance (\\(d_{ij}\\) in \\(m^2\\)) is the distance between the centroid of the polygon (i.e. areas features) or the point (i.e. point feature) and the centroid of the grid cells. 5.1 Features 5.1.1 Areal features The selected features and their expected effect on housing prices are reported in Table 5.1. Hospital, and Schools (e.g. schools) may create traffic and noise. Therefore, they may have a negative effect on housing prices (Gultekin and Yamamura (2006)). # List of OSM data # Available features: https://wiki.openstreetmap.org/wiki/Map_features osm_poly_list &lt;- tribble( ~feature, ~key, ~value, ~exp_effect, # Transportation &quot;Parking&quot;, &quot;amenity&quot;, &quot;parking&quot;, &quot;positive&quot;, # Green areas &quot;Park&quot;, &quot;leisure&quot;, c(&quot;park&quot;, &quot;garden&quot;, &quot;playground&quot;), &quot;positive&quot;, &quot;Allotment&quot;, &quot;landuse&quot;, &quot;allotments&quot;, &quot;positive&quot;, &quot;Meadow&quot;, &quot;landuse&quot;, &quot;meadow&quot;, &quot;positive&quot;, # Recreation ground &quot;Recreation&quot;, &quot;landuse&quot;, &quot;recreation_ground&quot;, &quot;positive&quot;, # Education &quot;School&quot;, &quot;amenity&quot;, c(&quot;school&quot;, &quot;kindergarten&quot;), &quot;negative&quot;, &quot;University&quot;, &quot;amenity&quot;, c(&quot;university&quot;, &quot;college&quot;), &quot;positive&quot;, # Healthcare &quot;Hospital&quot;, &quot;amenity&quot;, c(&quot;hospital&quot;), &quot;negative&quot; ) osm_poly_list &lt;- osm_poly_list %&gt;% unnest(c(value)) %&gt;% as.data.table() osm_poly_list %&gt;% group_by(feature, key, exp_effect) %&gt;% summarise(value = paste(value, collapse = &quot;, &quot;)) %&gt;% relocate(value, .after = key) %&gt;% kbl(caption = &quot;Expeced effect of polygon features on housing prices&quot;) %&gt;% kable_paper() Table 5.1: Expeced effect of polygon features on housing prices feature key value exp_effect Allotment landuse allotments positive Hospital amenity hospital negative Meadow landuse meadow positive Park leisure park, garden, playground positive Parking amenity parking positive Recreation landuse recreation_ground positive School amenity school, kindergarten negative University amenity university, college positive # Bounding of the study area (approx. buffer of 2km) box &lt;- c(xmin = 714906, xmax = 733618, ymin = 6166579, ymax = 6184092) bbox &lt;- st_bbox(box) bbox_sf &lt;- st_as_sfc(bbox) %&gt;% st_set_crs(&quot;EPSG:25832&quot;) # Get polygons osm_poly_dnld &lt;- oe_get(place = &quot;Copenhagen&quot;, layer = &quot;multipolygons&quot;, extra_tags = c(&quot;building&quot;, &quot;railway&quot;), provider = &quot;bbbike&quot;) %&gt;% # Convert to data.table as.data.table() %&gt;% # Long format melt(id.vars = c(&quot;osm_id&quot;, &quot;osm_way_id&quot;, &quot;type&quot;, &quot;name&quot;, &quot;geometry&quot;), variable.name = &quot;key&quot;, value.name = &quot;value&quot;) # Reading layer `multipolygons&#39; from data source `C:\\OSM_data\\bbbike_Copenhagen.gpkg&#39; using driver `GPKG&#39; # Simple feature collection with 377023 features and 26 fields # Geometry type: MULTIPOLYGON # Dimension: XY # Bounding box: xmin: 12.3 ymin: 55.6 xmax: 12.7 ymax: 55.8 # Geodetic CRS: WGS 84 # Merge and convert to sf osm_poly &lt;- merge(osm_poly_list, osm_poly_dnld, by = c(&quot;key&quot;, &quot;value&quot;)) %&gt;% # Convert to sf object st_sf() %&gt;% # Transform CRS st_transform(&quot;EPSG:25832&quot;) %&gt;% # Remove non-valid polygons (i.e. 2 polygons) mutate(valid = st_is_valid(.)) %&gt;% filter(!is.na(valid)) %&gt;% # From Meadow get only &quot;Kalvebod Fælled&quot; filter(feature != &quot;Meadow&quot; | (key == &quot;landuse&quot; &amp; value == &quot;meadow&quot; &amp; name == &quot;Kalvebod Fælled&quot;)) %&gt;% mutate(feature = case_when(feature == &quot;Meadow&quot; ~ &quot;Kalvebod_Fælled&quot;, TRUE ~ feature)) %&gt;% # Mass of the service (area of the polygons) mutate(m_service = as.numeric(units::set_units(st_area(.), m^2))) %&gt;% # crop to Bounding of the study area %&gt;% st_crop(bbox_sf) %&gt;% # Nest by feature group_by(feature) %&gt;% nest() %&gt;% ungroup() %&gt;% rename(data_poly = data) %&gt;% # Get centroids mutate(data_points = map(data_poly, st_centroid)) Spatial distribution (Figure 5.1) osm_poly %&gt;% unnest(cols = c(data_poly)) %&gt;% st_sf() %&gt;% ggplot() + geom_sf(data = st_crop(dk_country, bbox_sf), fill = &quot;grey95&quot;) + geom_sf(data = cph_parish, fill = &quot;grey85&quot;, color = &quot;grey50&quot;, size = 0.05) + geom_sf(fill = &quot;#D55E00&quot;, col = NA) + labs(caption = &quot;Source: Open Street Map&quot;) + theme_void() + facet_wrap(~feature) Figure 5.1: Spatial distribution of OSM areal features 5.1.2 Point features Point features and their expected effect on housing prices (Table 5.2). # Sustenance (points) osm_points_list &lt;- tribble( ~feature, ~key, ~value, ~exp_effect, # Sustenance &quot;Sustenance&quot;, &quot;amenity&quot;, c(&quot;bar&quot;, &quot;biergarten&quot;, &quot;cafe&quot;, &quot;fast_food&quot;, &quot;food_court&quot;, &quot;ice_cream&quot;, &quot;pub&quot;, &quot;restaurant&quot;), &quot;negative&quot;, # Shops &quot;Shop&quot;, &quot;shop&quot;, c(&quot;supermarket&quot;, &quot;mall&quot;, &quot;general&quot;, &quot;dairy&quot;, &quot;department_store&quot;, &quot;butcher&quot;, &quot;seafood&quot;, &quot;bakery&quot;, &quot;convenience&quot;), &quot;positive&quot;, # Entertainment, Arts &amp; Culture.... &quot;Entmt_pos&quot;, &quot;amenity&quot;, c(&quot;cinema&quot;, &quot;social_centre&quot;, &quot;theatre&quot;, &quot;community_centre&quot;, &quot;arts_centre&quot;, &quot;public_bookcase&quot;), &quot;positive&quot;, &quot;Entmt_neg&quot;, &quot;amenity&quot;, c(&quot;brothel&quot;, &quot;casino&quot;, &quot;gambling&quot;, &quot;love_hotel&quot;, &quot;nightclub&quot;, &quot;stripclub&quot;, &quot;swingerclub&quot;), &quot;negative&quot;, # Healthcare &quot;Social_fac&quot;, &quot;amenity&quot;, &quot;social_facility&quot;, &quot;negative&quot;, # Public transport &quot;Underground&quot;, &quot;railway&quot;, &quot;subway_entrance&quot;, &quot;positive&quot;, &quot;Bus_stop&quot;, &quot;highway&quot;, &quot;bus_stop&quot;, &quot;positive&quot;, &quot;Train_stop&quot;, &quot;railway&quot;, &quot;stop&quot;, &quot;positive&quot;) %&gt;% unnest(cols = c(value)) %&gt;% as.data.table() osm_points_list %&gt;% group_by(feature, key, exp_effect) %&gt;% summarise(value = paste(value, collapse = &quot;, &quot;)) %&gt;% relocate(value, .after = key) %&gt;% kbl(caption = &quot;Expeced effect of points features on housing prices&quot;) %&gt;% kable_paper() Table 5.2: Expeced effect of points features on housing prices feature key value exp_effect Bus_stop highway bus_stop positive Entmt_neg amenity brothel, casino, gambling, love_hotel, nightclub, stripclub, swingerclub negative Entmt_pos amenity cinema, social_centre, theatre, community_centre, arts_centre, public_bookcase positive Shop shop supermarket, mall, general, dairy, department_store, butcher, seafood, bakery, convenience positive Social_fac amenity social_facility negative Sustenance amenity bar, biergarten, cafe, fast_food, food_court, ice_cream, pub, restaurant negative Train_stop railway stop positive Underground railway subway_entrance positive osm_points_dnld &lt;- oe_get(place = &quot;Copenhagen&quot;, layer = &quot;points&quot;, extra_tags = c(&quot;amenity&quot;, &quot;shop&quot;, &quot;railway&quot;, &quot;highway&quot;), provider = &quot;bbbike&quot;) %&gt;% # Convert to data.table as.data.table() %&gt;% # Long format melt(id.vars = c(&quot;osm_id&quot;, &quot;name&quot;, &quot;address&quot;, &quot;geometry&quot;), variable.name = &quot;key&quot;, value.name = &quot;value&quot;) # Reading layer `points&#39; from data source `C:\\OSM_data\\bbbike_Copenhagen.gpkg&#39; using driver `GPKG&#39; # Simple feature collection with 399818 features and 13 fields # Geometry type: POINT # Dimension: XY # Bounding box: xmin: 12.3 ymin: 55.6 xmax: 12.7 ymax: 55.8 # Geodetic CRS: WGS 84 osm_points &lt;- merge(osm_points_list, osm_points_dnld, by = c(&quot;key&quot;, &quot;value&quot;)) %&gt;% # Convert to sf object st_sf() %&gt;% # Transform CRS st_transform(&quot;EPSG:25832&quot;) %&gt;% # crop to Bounding of the study area %&gt;% st_crop(bbox_sf) %&gt;% # Mass of the service (The same for all points = 1) mutate(m_service = 1) %&gt;% # Nest by feature group_by(feature) %&gt;% nest() %&gt;% rename(data_points = data) Spatial distribution (Figure 5.2) osm_points %&gt;% unnest(cols = c(data_points)) %&gt;% st_sf() %&gt;% ggplot() + geom_sf(data = st_crop(dk_country, bbox_sf), fill = &quot;grey95&quot;) + geom_sf(data = cph_parish, fill = &quot;grey85&quot;, color = &quot;grey50&quot;, size = 0.05) + geom_sf(colour = &quot;#D55E00&quot;, size = 0.5) + labs(caption = &quot;Source: Open Street Map&quot;) + theme_void() + facet_wrap(~feature) Figure 5.2: Spatial distribution of OSM point features 5.2 Potential model We have used exponential functions with impedance factors of 2 and spans of 5000m, 500m, or 300m depending on the service we modelled (Table 5.3). # Based on: https://riatelab.github.io/potential/articles/potential.html # Set Spatial Interaction Function (fun, span, beta) sif &lt;- tribble( ~feature, ~fun, ~span, ~beta, &quot;Kalvebod_Fælled&quot;, &quot;e&quot;, 5000, 2, &quot;Recreation&quot;, &quot;e&quot;, 500, 2, &quot;Train_stop&quot;, &quot;e&quot;, 500, 2, &quot;Underground&quot;, &quot;e&quot;, 500, 2, &quot;Parking&quot;, &quot;e&quot;, 300, 2, &quot;Park&quot;, &quot;e&quot;, 300, 2, &quot;School&quot;, &quot;e&quot;, 300, 2, &quot;University&quot;, &quot;e&quot;, 300, 2, &quot;Hospital&quot;, &quot;e&quot;, 300, 2, &quot;Allotment&quot;, &quot;e&quot;, 300, 2, &quot;Sustenance&quot;, &quot;e&quot;, 300, 2, &quot;Entmt_pos&quot;, &quot;e&quot;, 300, 2, &quot;Entmt_neg&quot;, &quot;e&quot;, 300, 2, &quot;Social_fac&quot;, &quot;e&quot;, 300, 2, &quot;Shop&quot;, &quot;e&quot;, 300, 2, &quot;Bus_stop&quot;, &quot;e&quot;, 300, 2 ) sif %&gt;% group_by(fun, beta, span,) %&gt;% summarise(feature = paste(feature, collapse = &quot;, &quot;)) %&gt;% relocate(feature, .after = span) %&gt;% kbl(caption = &quot;Spatial interaction parameters&quot;) %&gt;% kable_paper() Table 5.3: Spatial interaction parameters fun beta span feature e 2 300 Parking, Park, School, University, Hospital, Allotment, Sustenance, Entmt_pos, Entmt_neg, Social_fac, Shop, Bus_stop e 2 500 Recreation, Train_stop, Underground e 2 5000 Kalvebod_Fælled The spatial interaction functions are therefero as follow (Figure 5.3). par(mfrow=c(2,2)) plot_inter(fun = &quot;e&quot;, span = 300, beta = 2) plot_inter(fun = &quot;e&quot;, span = 500, beta = 2) plot_inter(fun = &quot;e&quot;, span = 5000, beta = 2) Figure 5.3: Spatial interaction functions # Merge all OMS features (as points) OMS &lt;- osm_poly %&gt;% select(feature, data_points) %&gt;% bind_rows(osm_points) %&gt;% # Add SIF parameters left_join(sif, by = &quot;feature&quot;) # Aux. function for calculating the potential f_pot &lt;- function(df, fun, span, beta) { mcpotential(x = df, y = grids100m$data_points[[1]], var = &quot;m_service&quot;, fun = fun, span = span, beta = beta, limit = 5 * span) } # Estimate potential (in percentage - relatively to the maximum) pot_est &lt;- list() for(i in seq_along(OMS$data_points)) { # Values potential &lt;- f_pot(OMS$data_points[[i]], OMS$fun[i], OMS$span[i], OMS$beta[i]) # Percentage relatively to the maximum pot_est[[i]] &lt;- 100 * potential / max(potential) # Add names names(pot_est)[[i]] &lt;- OMS$feature[i] } # Add values to the grid cells of 100 x 100 m (grids100m) pot &lt;- rbind(pot_est) %&gt;% as_tibble() %&gt;% unnest(everything()) grids100m &lt;- grids100m %&gt;% bind_cols(pot %&gt;% nest(pot = everything())) Potential model (Figure 5.4) # Plots grids100m %&gt;% select(data_poly, pot) %&gt;% unnest(c(data_poly, pot)) %&gt;% pivot_longer(-c(grid_ID, geometry), names_to = &quot;feature&quot;, values_to = &quot;value&quot;) %&gt;% st_sf() %&gt;% ggplot() + geom_sf(aes(fill = value), col = NA) + scale_fill_viridis_c(name = &quot;[%]&quot;, option = &quot;magma&quot;, direction = -1) + geom_sf(data = cph_parish, fill = NA, color = &quot;grey50&quot;, size = 0.05) + theme_void() + facet_wrap(~feature) Figure 5.4: Potential model "],["dist-CBD.html", "Chapter 6 Distance to Central Business District", " Chapter 6 Distance to Central Business District The distance between a house and the Central Business District (CBD) has an important role in its price (Chen and Hao (2008)). We add thereofre it as another feature in our model, with a possitive expected effec (i.e. the closer the house to the CBT, the higer the price). However, we do not measure the distance in km but the commuting time from the house to the CBD (i.e. Indre By). In this regard, we estimate the travel time (in public transport) from the centre of each grid cell of 100m x 100m to Kongens Nytorv (coordinates: 55.6805° N, 12.5860° E), and we associate the time to all dwellings at that grid. We have used used the open source OpenTripPlanner, and the r-package opentripplanner (Morgan et al. (2019)) for calculating the travel times by foot, bike, car, and public transport (Figure 6.1). # Kongens Nytorv KN &lt;- tibble(name = &quot;Kongens Nytorv&quot;, x = 12.5860, y = 55.6805) %&gt;% st_as_sf(coords = c(&quot;x&quot;, &quot;y&quot;)) %&gt;% st_set_crs(&quot;EPSG:4326&quot;) # OTP folder structure dir.create(&quot;otp&quot;) dir.create(&quot;otp/graphs/default&quot;) path_data &lt;- file.path(&quot;./otp&quot;) # Data ## Download Denmark GTFS from dk_gtfs &lt;- &quot;http://www.rejseplanen.info/labs/GTFS.zip&quot; ## and save as &quot;~./otp/graphs/default/gtfs.zip&quot;) ## Copenhagen pbf cph_match &lt;- oe_match(&quot;Copenhagen&quot;, provider = &quot;bbbike&quot;, quiet = TRUE) oe_download(cph_match$url, provider = &quot;bbbike&quot;, download_directory = &quot;./otp/graphs/default&quot;, quiet = TRUE) file.rename(from = &quot;./otp/graphs/default/bbbike_Copenhagen.osm.pbf&quot;, to = &quot;./otp/graphs/default/osm.pbf&quot;) ## Get DEM # Download elevation model (10m resolution) zip_files &lt;- c(&quot;DTM10_616_71_ASC_UTM32-EUREF89.ZIP&quot;, &quot;DTM10_616_72_ASC_UTM32-EUREF89.ZIP&quot;, &quot;DTM10_617_71_ASC_UTM32-EUREF89.ZIP&quot;, &quot;DTM10_617_72_ASC_UTM32-EUREF89.ZIP&quot;, &quot;DTM10_618_71_ASC_UTM32-EUREF89.ZIP&quot;, &quot;DTM10_618_72_ASC_UTM32-EUREF89.ZIP&quot;) f1 &lt;- function(zip_file){ dangeo_get_data(ftp_folder = &quot;dhm_danmarks_hoejdemodel/DHM-HISTORIK/DHM-2007/DTM_10M&quot;, zip_name = zip_file) } map(zip_files, f1) # Read files asc_files_path &lt;- list.files(path = loc_dir , pattern = &quot;*.asc&quot;, full.names = TRUE, recursive = TRUE) # Read blocks dtm10_blocks &lt;- map(.x = asc_files_path, .f = read_stars) # Set crs (UTM32-ETRS89) dtm10_blocks &lt;- map(dtm10_blocks, ~st_set_crs(., st_crs(study_area))) # Build a mosaic dtm10 &lt;- st_mosaic(dtm10_blocks[[1]], dtm10_blocks[[2]], dtm10_blocks[[3]], dtm10_blocks[[4]], dtm10_blocks[[5]], dtm10_blocks[[6]]) # Intersect with study area cph_dtm10 &lt;- st_crop(dtm10, study_area) # Warping the raster newgrid &lt;- study_area %&gt;% st_transform(crs = &quot;EPSG:4326&quot;) %&gt;% st_bbox() %&gt;% st_as_stars(dx = 0.000065, dy = 0.000065) # approx. 10m cph_dtm10_WGS84 &lt;- cph_dtm10 %&gt;% st_warp(newgrid) # Export to otp folder write_stars(cph_dtm10_WGS84, &quot;otp/graphs/default/dem.tif&quot;) # Open Trip Planner ## Downloading OTP path_otp &lt;- otp_dl_jar() ## Building an OTP Graph log1 &lt;- otp_build_graph(otp = path_otp, dir = path_data, memory = 10240) ## Start OTP log2 &lt;- otp_setup(otp = path_otp, dir = path_data) ## Connect R to OTP otpcon &lt;- otp_connect() # Origin points op &lt;- grids100m$data_points[[1]] %&gt;% st_transform(crs = &quot;EPSG:4326&quot;) # Calculate travel times (i.e. walk, bike, car, and public transport) f_tt &lt;- function(feature){ otp_plan(otpcon = otpcon, fromPlace = op, toPlace = c(12.5860, 55.6805), get_geometry = FALSE, mode = feature, ncores = as.numeric(availableCores() - 1)) %&gt;% select(fromPlace, toPlace, duration) } dur_features &lt;- list(walk = &quot;WALK&quot;, bike = &quot;BICYCLE&quot;, car = &quot;CAR&quot;, transit = c(&quot;WALK&quot;, &quot;TRANSIT&quot;)) tt &lt;- map(dur_features, f_tt) # Intersect with grid cells of 100 x 100 m f1 &lt;- . %&gt;% as_tibble() %&gt;% mutate(duration = duration/60) %&gt;% separate(fromPlace, c(&quot;Y&quot;, &quot;X&quot;), sep = &quot;,&quot;) %&gt;% st_as_sf(coords = c(&quot;X&quot;, &quot;Y&quot;)) %&gt;% st_set_crs(&quot;EPSG:4326&quot;) %&gt;% st_transform(crs = &quot;EPSG:25832&quot;) %&gt;% st_intersection(grids100m$data_poly[[1]]) tt_grids_cent &lt;- tt %&gt;% map(~f1(.)) # Add to grids polygons f2 &lt;- . %&gt;% st_drop_geometry() %&gt;% left_join(as_tibble(grids100m$data_poly[[1]]), by = &quot;grid_ID&quot;) %&gt;% st_sf() tt_grids_poly &lt;- tt_grids_cent %&gt;% map(~f2(.)) f3 &lt;- function(feature){ tt_grids_poly %&gt;% pluck(feature) %&gt;% mutate(feature = feature) } tt_grids_poly &lt;- names(tt_grids_poly) %&gt;% map(~f3(.)) # Merge grids tt_cph_grids100m &lt;- bind_rows(tt_grids_poly) %&gt;% mutate(feature = factor(feature, levels = c(&quot;walk&quot;, &quot;bike&quot;, &quot;car&quot;, &quot;transit&quot;))) saveRDS(tt_cph_grids100m, file = &quot;travel_times_grids100m_otp.rds&quot;) # Stop OTP otp_stop(warn = FALSE) tt_cph_grids100m &lt;- readRDS(file = &quot;travel_times_grids100m_otp.rds&quot;) myPalette &lt;- RColorBrewer::brewer.pal(8, &quot;RdYlBu&quot;) ggplot() + geom_sf(data = tt_cph_grids100m, aes(fill = cut(duration, breaks = c(0, 10, 20, 30, 40, 50, 60, 120, ceiling(max(duration))), include.lowest = TRUE)), col = NA) + scale_fill_manual(name = &quot;min&quot;, values = rev(myPalette)) + geom_sf(data = cph_parish, fill = NA, color = &quot;grey50&quot;, size = 0.05) + geom_sf(data = KN, color = &quot;black&quot;, shape = 16, size = 1.5) + theme_void() + facet_wrap(~feature) Figure 6.1: Travel times to Kongens Nytorv (black point) "],["EDA-house-prices.html", "Chapter 7 Residential units saled as free scale 7.1 Residential units by floor level", " Chapter 7 Residential units saled as free scale We focused our study in residential dwellings on the ordinary free trade (Table 3.2). NOTES: There are large differences in the number of residential units between years, why?? Study only one year for the moment (e.g. 2019)?? Housing prices in different years -&gt; adjust to 2019 prices (what index; Table 3.1)? KONTANT_KOEBESUM = cash purchase price? Analyse it?? What about KOEBESUM_BELOEB = The purchase price agreed upon the sale of the property??? KONTANT_KOEBESUM = 0 or (&lt; 100000 DKK)? SKOEDE_DATO = The date on which the deed was signed -&gt; use as sale date?? Should we use this date (i.e. for the price index)?  What about housing prices = 0? Dwelling Area &lt;= 0? res_units_oft %&gt;% ggplot(aes(sample = log10(price2019_kDKK), colour = factor(BBR_year))) + geom_qq() + #geom_qq_line() + facet_grid(~type) + theme_bw() 7.1 Residential units by floor level KL - basement ST - ground floor 1 - 1st floor 2 - 2nd floor 3 - 3rd floor 4 - 4th floor 5 or more = etc. res_units_oft %&gt;% group_by(floor_level, type) %&gt;% summarise(n = n()) %&gt;% ungroup() %&gt;% # in percentage [%] mutate(perc = 100 * n / sum(n)) %&gt;% # Reorder type levels for plotting multi-storey first mutate(type = factor(type)) %&gt;% ggplot() + geom_bar(aes(y = floor_level, x = perc, fill = type), stat = &quot;identity&quot;) + labs(y = &quot;&quot;, x = &quot;Percentage [%]&quot;) + theme_bw() + theme(legend.position = &quot;bottom&quot;, legend.title = element_blank()) + guides(fill = guide_legend(ncol = 2)) + scale_x_continuous(labels = scales::comma) + scale_fill_manual(values = c(&quot;#0072B2&quot;, &quot;#D55E00&quot;, &quot;#CC79A7&quot;)) Figure 7.1: Residential units distribution by floor level "],["references.html", "References", " References Chen, Jie, and Qianjin Hao. 2008. The impacts of distance to CBD on housing prices in Shanghai: a hedonic analysis. Journal of Chinese Economic and Business Studies 6 (3): 291302. https://doi.org/10.1080/14765280802283584. Giraud, Timothée, and Hadrien Commenges. 2020. potential: Implementation of the Potential Model. R Package Version 0.1.0. https://cran.r-project.org/package=potential. Gultekin, Bahadir, and Etsuo Yamamura. 2006. Potential and Network Analysis Application of Estimating Housing Prices in Northern District of Sapporo. Studies in Regional Science 35 (4): 1097107. https://doi.org/10.2457/srs.35.1097. Morgan, Malcolm, Marcus Young, Robin Lovelace, and Layik Hama. 2019. OpenTripPlanner for R. Journal of Open Source Software 4 (44): 1926. https://doi.org/10.21105/joss.01926. Valtersdorf Møller, Katrine. 2020. The influence of traffic noise on house prices. Aalborg University. https://projekter.aau.dk/projekter/files/334368384/Thesis{\\_}without{\\_}appendix.pdf. Weber, Christiane, and Jacky Hirsch. 2000. Potential model application and planning issues. Cybergeo, no. 1995 (March). https://doi.org/10.4000/cybergeo.889. "]]
