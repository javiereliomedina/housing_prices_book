[["index.html", "Housing prices Copenhagen Prerequisite R session", " Housing prices Copenhagen Javier Elío, Henning S. Hansen, Carsten Keßler 2021-04-19 Prerequisite The data have been analysed with R (version 4.0.4) and Rstudio (version 1.4.1106), and the book has been created with bookdown package. The required packages are automatically checked and installed if needed from CRAN. # Create an auxiliary function for checking if a package is installed, # install it if it is not, and load the package # (based on https://gist.github.com/stevenworthington/3178163) ipak &lt;- function(pkg){ new_pkg &lt;- pkg[!(pkg %in% installed.packages()[, &quot;Package&quot;])] if (length(new_pkg)) install.packages(new_pkg, dependencies = TRUE, repos = &quot;http://cran.us.r-project.org&quot;) sapply(pkg, require, character.only = TRUE) } # List of packages pkg &lt;- c(&quot;bit64&quot;, &quot;bookdown&quot;, &quot;data.table&quot;, &quot;danstat&quot;, &quot;forcats&quot;, &quot;furrr&quot;, &quot;ggspatial&quot;, &quot;giscoR&quot;, &quot;gtsummary&quot;, &quot;janitor&quot;, &quot;kableExtra&quot;, &quot;knitr&quot;, &quot;latex2exp&quot;, &quot;osmdata&quot;, &quot;patchwork&quot;, &quot;potential&quot;, &quot;rmarkdown&quot;, &quot;remotes&quot;, &quot;RColorBrewer&quot;, &quot;rappdirs&quot;, &quot;sf&quot;, &quot;stringr&quot;, &quot;SnowballC&quot;, &quot;stars&quot;, &quot;units&quot;, &quot;table1&quot;, &quot;tidyverse&quot;, &quot;tidytext&quot;, &quot;tm&quot;, &quot;tools&quot;) # Check and install ipak(pkg) Furthermore, we have created our own package for downloading kortforsyningen data to a local repository directly from R (i.e. dangeo). The package can be downloaded from GitHub: # Install package from GitHub if (!require(&quot;dangeo&quot;)) remotes::install_github(&quot;javiereliomedina/dangeo&quot;) library(dangeo) Although the kortforsyningen data are free, we would need to create a username and a password for getting access to them (you can make it here: Opret ny bruger). By default dangeo looks for credentials on .Renviron as: kortforsyningen_id = \"username\" and kortforsyningen_pwd = \"password\". You would need to save them with usethis::edit_r_environ(): # Set username and password # usethis::edit_r_environ() # Open .Renviron file, and save the username (kortforsyningen_id = &quot;your_username&quot;) and password (kortforsyningen_pwd = &quot;your_password&quot;) You would also need to define with dangeo_set_param() the local directory where the data are downloaded (loc_dir). It is defined as loc_dir = rappdirs::user_cache_dir(), although it can be changed loc_dir = ./your/local/path. The first time a file is downloaded with dangeo_get_data(), the process can be time consuming (there are some very big files). However, it will not be downloaded in subsequent calls if the files is already in the local directory (the dataset can be overwritten be setting overwrite = TRUE on dangeo_get_data()). Once we have our username and password, and we have define the local repository for the data, we can set them on our R-session: # Set local repository and password to kortforsyningen dangeo_set_param() Finally, the BBR data are storage in a OneDrive folder. You would need to have access to that folder, and save the path on .Renviron with usethis::edit_r_environ(). It has to be saved as OneDrive_BBR_path = \"your/OneDrive/BBR/path\". R session # R version 4.0.4 (2021-02-15) # Platform: x86_64-w64-mingw32/x64 (64-bit) # Running under: Windows 10 x64 (build 17763) # # Matrix products: default # # locale: # [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 # [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C # [5] LC_TIME=English_United Kingdom.1252 # # attached base packages: # [1] tools stats graphics grDevices utils datasets methods base # # other attached packages: # [1] dangeo_0.0.0.9000 tm_0.7-8 NLP_0.2-1 tidytext_0.3.0 dplyr_1.0.5 purrr_0.3.4 # [7] readr_1.4.0 tidyr_1.1.3 tibble_3.1.0 ggplot2_3.3.3 tidyverse_1.3.0 table1_1.3 # [13] units_0.7-1 stars_0.5-2 abind_1.4-5 SnowballC_0.7.0 stringr_1.4.0 sf_0.9-8 # [19] rappdirs_0.3.3 RColorBrewer_1.1-2 remotes_2.2.0 rmarkdown_2.7 potential_0.1.0 patchwork_1.1.1 # [25] osmdata_0.1.5 latex2exp_0.5.0 knitr_1.31 kableExtra_1.3.4 janitor_2.1.0 gtsummary_1.4.0 # [31] giscoR_0.2.2 ggspatial_1.1.5 furrr_0.2.2 future_1.21.0 forcats_0.5.1 danstat_0.1.0 # [37] data.table_1.14.0 bookdown_0.21 bit64_4.0.5 bit_4.0.4 # # loaded via a namespace (and not attached): # [1] colorspace_2.0-0 ellipsis_0.3.1 class_7.3-18 snakecase_0.11.0 fs_1.5.0 # [6] rstudioapi_0.13 proxy_0.4-25 listenv_0.8.0 fansi_0.4.2 lubridate_1.7.9.2 # [11] xml2_1.3.2 codetools_0.2-18 splines_4.0.4 Formula_1.2-4 jsonlite_1.7.2 # [16] gt_0.2.2 broom_0.7.6 dbplyr_2.1.0 compiler_4.0.4 httr_1.4.2 # [21] backports_1.2.1 assertthat_0.2.1 Matrix_1.3-2 cli_2.4.0 htmltools_0.5.1.1 # [26] gtable_0.3.0 glue_1.4.2 Rcpp_1.0.6 slam_0.1-48 cellranger_1.1.0 # [31] jquerylib_0.1.3 vctrs_0.3.7 svglite_2.0.0 broom.helpers_1.3.0 lwgeom_0.2-5 # [36] xfun_0.22 globals_0.14.0 rvest_1.0.0 lifecycle_1.0.0 scales_1.1.1 # [41] hms_1.0.0 parallel_4.0.4 yaml_2.2.1 curl_4.3 sass_0.3.1 # [46] stringi_1.5.3 tokenizers_0.2.1 e1071_1.7-6 rlang_0.4.10 pkgconfig_2.0.3 # [51] systemfonts_1.0.1 evaluate_0.14 lattice_0.20-41 tidyselect_1.1.0 parallelly_1.24.0 # [56] magrittr_2.0.1 R6_2.5.0 generics_0.1.0 DBI_1.1.1 pillar_1.6.0 # [61] haven_2.3.1 withr_2.4.1 survival_3.2-10 sp_1.4-5 janeaustenr_0.1.5 # [66] modelr_0.1.8 crayon_1.4.1 KernSmooth_2.23-18 utf8_1.2.1 grid_4.0.4 # [71] readxl_1.3.1 isoband_0.2.4 reprex_1.0.0 digest_0.6.27 classInt_0.4-3 # [76] webshot_0.5.2 munsell_0.5.0 viridisLite_0.4.0 bslib_0.2.4 "],["hedonic-price-model.html", "Chapter 1 Hedonic price model 1.1 House characteristics 1.2 Location characteristics 1.3 Neighbourhood characteristics", " Chapter 1 Hedonic price model House prices can be modelled based on the structural characteristics of the house (e.g. age, size, building materials, floor level, etc.), their location (e.g. proximity to urban services, distance to Central Business District - CBD, accessibility, etc.), and the surrounding environment (e.g. neighbourhood services and socio-economic aspects of its inhabitants, leisure facilities, noise levels, etc.) (Chen and Hao (2008), Gultekin and Yamamura (2006)). We will focus our study in the socio-economic aspects of the neighbourhood and, in particular, in the migration structure (e.g. migration pressure, ethnic groups, ). The house prices can be therefore defined by the following function (Chen and Hao (2008), Gultekin and Yamamura (2006)). \\[P_i = f(H_i, L_i, N_i) + \\epsilon \\] Where \\(f\\) represents the functional function in the hedonic model, P is the price of the house i, and \\(H_i\\), \\(L_i\\) and \\(N_i\\) are the vector of the structural characteristics, the location variables, and the neighbourhood characteristics of the house i, respectively. Finally, \\(\\epsilon\\) is the error term. 1.1 House characteristics We get the housing prices and the house properties from the Building and Dwelling Register (BBR). The dataset contains information about the building (e.g. building area, renovation year, etc.) and the residential unit (e.g. size, number of rooms, floor level, etc.). The data from residential units are unique for each dwelling, while some building characteristics are shared by several dwellings. We therefore merge both dataset for getting a dataset in which each row represents only one dwelling. There are data from 2006 to 2019. 1.2 Location characteristics OpenStreetMaps and kortforsyningen were used for getting the data about the urban services (e.g. public transport network, parks, ). Then, the interaction between those services and the house was modelled by potential models (Weber and Hirsch (2000), Gultekin and Yamamura (2006)), where the intensity of the interaction between the elements and the house is inversely proportional to the distance between them (Giraud and Commenges (2020)). \\[ p_i = \\sum_{j = i}^{n} M_i \\cdot f(d_{ij}) \\] Where \\(p_i\\) is the potential of the housing unit, \\(M_j\\) the mass of the service, and \\(f(d_{ij})\\) the negative function of the distance between the dwelling i and the service j. 1.3 Neighbourhood characteristics We have used the smallest administrative area of Denmark (i.e. parish) for evaluating the influence of the neighbourhoog characteristics on housing prices (Use also potential model here -&gt; e.g. locate the stock of migrant population on the centroid of each parish and get the interaction intensity in each house??). The following tables from the Denmark Statistics were used: SOGN10B: Disposable income for households by parish, price unit and income. SOGN05: Population (end November) by parish, socioeconomic status and sex SOGN07: Households disposal of vehicles by parish and use of cars (do you think it could be relevant? Do people think on parking issues when they buy a house?) KMSTA003: Summary vital statistics by parish and movements KMSTA001: Population 1. January by parish, ancestry and member of the National Church. VAN1AAR: Immigration (yearly) by municipality, sex, age, country of origin and citizenship Can we also have this dataset at parish level? "],["administrative-units.html", "Chapter 2 Administrative units", " Chapter 2 Administrative units The Denmarks Administrative Geographical Division (DAGI) has been used for obtaining the administrative boundaries of Denmark. In this sense, the country is divided in approx. 2200 parishes, 98 municipalities, 5 regions, 22 judicial districts, 12 police districts, 92 constituencies and approx. 1100 postcodes. However, we focused our study in the Copenhagen (KOMKODE = 0101) and Frederiksberg (KOMKODE = 0147) communes. # Download DAGI (scale 1:10000) dangeo_get_data(ftp_folder = &quot;landinddelinger/dagi/SHAPE&quot;, zip_name = &quot;DAGIREF_SHAPE_UTM32-EUREF89.zip&quot;) # Codes of the communes under study (KOMKODE) study_area_codes &lt;- c(&quot;0101&quot;, &quot;0147&quot;) # Communes polygons of Denmark, and select those in the study area commune_link &lt;- paste(loc_dir, &quot;DAGIREF_SHAPE_UTM32-EUREF89/ADM&quot;, &quot;KOMMUNE.shp&quot;, sep = &quot;/&quot;) dk_commune &lt;- read_sf(commune_link) %&gt;% st_zm() %&gt;% st_transform(crs = &quot;EPSG:25832&quot;) cph_commune &lt;- filter(dk_commune, KOMKODE %in% study_area_codes) # Parishes polygons of Denmark, and select those in the study area parish_link &lt;- paste(loc_dir, &quot;DAGIREF_SHAPE_UTM32-EUREF89/ADM&quot;, &quot;SOGN.shp&quot;, sep = &quot;/&quot;) dk_parish &lt;- read_sf(parish_link) %&gt;% st_zm() %&gt;% st_transform(crs = &quot;EPSG:25832&quot;) # Select those where the centroid is in the study area dk_parish_cent &lt;- st_centroid(dk_parish) cph_parish_cent &lt;- st_intersection(dk_parish_cent, cph_commune) cph_parish &lt;- filter(dk_parish, SOGNEKODE %in% cph_parish_cent$SOGNEKODE) %&gt;% # Combine several parish features geometries into one polygon group_by(SOGNEKODE, SOGNENAVN) %&gt;% summarise(geometry = st_union(geometry)) %&gt;% ungroup() %&gt;% # add area of the parish (in km2) mutate(prsh_area_km2 = as.numeric(units::set_units(st_area(.), km^2))) # Contour of the study area (merge the parishes in one polygon): study_area &lt;- cph_parish %&gt;% st_union() %&gt;% st_sf() %&gt;% st_transform(crs = &quot;EPSG:25832&quot;) # Plot parish ggplot() + geom_sf(data = cph_parish, fill = &quot;grey&quot;, color = &quot;grey50&quot;, size = 0.05) + my_theme_map() + annotation_scale(location = &quot;br&quot;, text_cex = 1) + annotation_north_arrow(location = &quot;br&quot;, pad_x = unit(1.6, &quot;cm&quot;), pad_y = unit(0.65, &quot;cm&quot;), which_north = &quot;true&quot;, height = unit(0.5, &quot;cm&quot;), width = unit(0.5, &quot;cm&quot;), style = north_arrow_orienteering(text_col = &quot;white&quot;, text_size = 1)) Figure 2.1: Parishes in the study area We have also created grid cells of 100m x 100m for aggregating some data at that scale (i.e. population density). # Make grids grids100m &lt;- study_area %&gt;% # Make regular grids (100m x 100m) st_make_grid(cellsize = 100) %&gt;% st_sf() %&gt;% # Select grids only in the study area mutate(int = st_intersects(., study_area) %&gt;% lengths &gt; 0) %&gt;% filter(int == TRUE) %&gt;% # Name grids as &quot;g001&quot;, &quot;g002&quot;, ... mutate(grid_ID = paste0(&quot;g&quot;, stringr::str_pad(seq(1, nrow(.), 1), 3, pad = &quot;0&quot;))) # Plot ggplot() + geom_sf(data = cph_parish, fill = &quot;grey&quot;, color = &quot;grey50&quot;, size = 0.05) + geom_sf(data = grids100m, fill = NA, color = &quot;red&quot;, size = 0.05) + my_theme_map() + annotation_scale(location = &quot;br&quot;, text_cex = 1) + annotation_north_arrow(location = &quot;br&quot;, pad_x = unit(1.6, &quot;cm&quot;), pad_y = unit(0.65, &quot;cm&quot;), which_north = &quot;true&quot;, height = unit(0.5, &quot;cm&quot;), width = unit(0.5, &quot;cm&quot;), style = north_arrow_orienteering(text_col = &quot;white&quot;, text_size = 1)) Figure 2.2: Grid cells of 100m x 100m There are therefore a total number of 65 parishes (Figure 2.1 and 10786 grid cells (Figure 2.2) in the study area. The statistics for neighbourhood characteristics at parish level since they are the smallest administrative units in Denmark. "],["housing-data.html", "Chapter 3 Housing data", " Chapter 3 Housing data We load all buildings for year-round living (BYG_ANVEND_KODE) from the Building and Dwelling Register (BBR), we use this table for disaggregating population density from parish level to grid cells of 100m x 100m. 110 = Farmhouse for agricultural property. 120, 121, 122 = Detached single-family house (detached house). 130, 131, 132 = Townhouse, chain, or semi-detached house (vertical separation between the units). 140 = Multi-storey residential building (multi-family house, including two-family house (horizontal separation between the units). 150 = College. 160 = Residential building for residential institution. 190 = Second building for year-round living. # Buildings for year round living res_codes &lt;- tribble (~BYG_ANVEND_KODE, ~type, 110, &quot;Farmhouse&quot;, 120, &quot;Single-family house&quot;, 121, &quot;Single-family house&quot;, 122, &quot;Single-family house&quot;, 130, &quot;Semi-detached house&quot;, 131, &quot;Semi-detached house&quot;, 132, &quot;Semi-detached house&quot;, 140, &quot;Multi-storey&quot;, 150, &quot;College&quot;, 160, &quot;Residential institution&quot;, 190, &quot;Second building&quot;) %&gt;% # Convert type to factor mutate(type = factor(type)) # Function for reading residential units from a csv file: # Read residential units from BBR data # Get read residential units in an area # @param file Link to OneDrive with the data (.csv format) # @param area Area where we would get the data (default = study_area) f_res_units &lt;- function(.file, .area = study_area) { fread(.file) %&gt;% # Convert to tibble as_tibble() %&gt;% # Select only Residential houses - Buildings for year-round living filter(ENH_ANVEND_KODE %in% res_codes$BYG_ANVEND_KODE) %&gt;% # Input empty cells (buildings with only one floor) in Etagebetegn as &quot;st&quot; mutate(Etagebetegn = ifelse(Etagebetegn == &quot;&quot;, &quot;st&quot;, Etagebetegn), # Etagebetegn as ordened factor Etagebetegn = factor(Etagebetegn, c(&quot;k2&quot;, &quot;kl&quot;, &quot;st&quot;, seq(1, 36, 1)), ordered = TRUE), # Group floor levels with 5 or more floor_level = fct_other(Etagebetegn, drop = factor(seq(5, 36)), other_level = &quot;5 or more&quot;)) %&gt;% # Add residential description (type) into the dataset left_join(res_codes, by = c(&quot;ENH_ANVEND_KODE&quot; = &quot;BYG_ANVEND_KODE&quot;)) %&gt;% # Convert to sf objects st_as_sf(coords = c(&quot;etrs89koordinat_ost&quot;, &quot;etrs89koordinat_nord&quot;), crs = &quot;EPSG:25832&quot;) %&gt;% # Get only points in the study area mutate(int = st_intersects(., .area) %&gt;% lengths &gt; 0) %&gt;% filter(int == TRUE) %&gt;% # Add year of the BBR dataset mutate(BBR_year = parse_number(stringr::str_extract(.file, &quot;_[0-9]+_&quot;))) %&gt;% # Convert columns with codes (*_KODE) to factors mutate(across(.cols = ends_with(&quot;_KODE&quot;), .fns = as_factor)) } # Load all csv files (one file for each year) in the same tibble with a column indicating the year of the dataset: # Load residential units # NOTE: you may need to change the path to OneDrive - Aalborg Universitet # Read all the data together csv_files_link &lt;- list.files(path = Sys.getenv(&quot;OneDrive_BBR_path&quot;), pattern = &quot;*.csv&quot;, full.names = TRUE) plan(multisession, workers = 3) res_units &lt;- future_map_dfr(.x = csv_files_link, .f = f_res_units) plan(&quot;default&quot;) However, for housing prices we focus our analysis to the main building types in Copenhagen, which are in this order: i) multi-storey residential buildings (multi-family house or two-family house), ii) detached single-family houses, iii) colleges, and iv) semi-detached houses (Figure 3.1). # Aux. function for plotting 2D kernel density maps: f &lt;- function(.data) { .data %&gt;% st_coordinates() %&gt;% as_tibble() %&gt;% ggplot() + geom_sf(data = cph_parish, fill = &quot;grey&quot;, color = &quot;grey50&quot;, size = 0.05) + geom_point(aes(X, Y), size = 0.02, shape = 16) + stat_density_2d(aes(X, Y, fill = ..level..), alpha = 0.5, h = 700, geom = &quot;polygon&quot;) + scale_fill_distiller(palette = &quot;Spectral&quot;) + theme_void() + theme(legend.position = &quot;none&quot;) + labs(title = .data$type, x = &quot;&quot;, y = &quot;&quot;) } # Plots p &lt;- res_units %&gt;% filter(BBR_year == 2019) %&gt;% # Reorder type factors by the frequency they appear mutate(type = fct_infreq(type)) %&gt;% # Split by house type group_split(type) %&gt;% map( ~ f(.)) wrap_plots(p) + annotation_scale(location = &quot;br&quot;, text_cex = 1) + annotation_north_arrow(location = &quot;br&quot;, pad_x = unit(0.70, &quot;cm&quot;), pad_y = unit(0.65, &quot;cm&quot;), which_north = &quot;true&quot;, height = unit(0.5, &quot;cm&quot;), width = unit(0.5, &quot;cm&quot;), style = north_arrow_orienteering(text_col = &quot;white&quot;, text_size = 1)) + plot_annotation(title = &quot;Residential units in 2019&quot;, theme = theme(plot.title = element_text(size = 14, colour = &quot;darkblue&quot;, face = &quot;bold&quot;), plot.caption = element_text(size = 9, colour = &quot;grey25&quot;) ) ) Figure 3.1: 2D kernel density map Then, we selected from the main residential buildings those that are on the ordinary free trade and are actually used for residential purpose (i.e. BOLIGTYPE_KODE \\(\\neq\\) E - Andet (bl.a. institutioner og erhverv)). Furthermore, dwelling with a size lower that 10 \\(m^2\\) were removed from the analysis. Colleges were also excluded from the data analysis since they are a special type of buildings dedicated to students residences mainly outside of the free marked. selected_res_units &lt;- c(&quot;Multi-storey&quot;, &quot;Single-family house&quot;, &quot;Semi-detached house&quot;) res_units_oft &lt;- res_units %&gt;% # Convert to tibble as_tibble() %&gt;% # Select main residential units in the area filter(type %in% selected_res_units) %&gt;% # ordinary free trade filter(OVERDRAGELSES_KODE == &quot;1&quot;) %&gt;% # Remove BOLIGTYPE_KODE = E form the dataset filter(BOLIGTYPE_KODE != &quot;E&quot;) %&gt;% # Remove tiny dwellings (area &lt; 10 m2) filter(BEBO_ARL &gt;= 10) %&gt;% # Drop unused factors levels droplevels() Finally, we adjusted the housing prices to 2019 prices. In this regard, we take into account the inflation and, therefore, prices from different years can be compared (Valtersdorf Møller (2020)). The adjusted price is obtained as follow: \\[ Pice_{2019} = Price_{i} \\cdot \\frac{Index_{2019}}{Index_{i}}\\] Where, \\(Price_{2019}\\) is the adjusted housing price for 2019, \\(Price_{i}\\) is the price of the respective year \\(i\\), and \\(Index_{i}\\) and \\(Index_{2019}\\) are the price indexes for the origin year \\({i}\\) and \\(2019\\), respectively. The indexes have been obtained from Statistic Denmark; i.e. table EJ66: Price index for sales property (2006=100) by region, category of real property and unit, and targeted for the study area; i.e. Province Byen København - Copenhagen City (Table 3.1). Inconsistent values have been removed; i.e. 2019 adjusted prices &lt; 10 kDKK (approx. 1300). # DST table (EJ66: Price index for sales property (2006=100) by region, category of real property and unit) id_table &lt;- &quot;EJ66&quot; dat_meta &lt;- get_table_metadata(table_id = id_table, variables_only = TRUE) # Values to retrieve variables &lt;- list( # Province Byen København: region = 01 list(code = &quot;OMRÅDE&quot;, values = &quot;01&quot;), # Category of real property list(code = &quot;EJENDOMSKATE&quot;, values = c(&quot;0111&quot;, &quot;2103&quot;)), # Index list(code = &quot;TAL&quot;, values = NA), # From 2004 to 2019 list(code = &quot;Tid&quot;, values = seq(2004, 2019, 1)) ) # Get index price_index &lt;- get_data(&quot;EJ66&quot;, variables) %&gt;% # Get index filter(TAL == &quot;Index&quot;) %&gt;% # Translate into English rename(region = OMRÅDE, category = EJENDOMSKATE, unit = TAL, date = TID, index = INDHOLD) %&gt;% # Convert index tu numeric mutate(index = as.numeric(index)) %&gt;% # Remove region and unit columns select(-region, -unit) # Print price index table price_index %&gt;% # Wide format pivot_wider(names_from = date, values_from = index) %&gt;% kbl(caption = &quot;Price index for sale properties in Copenhagen City&quot;) %&gt;% kable_paper() %&gt;% scroll_box(width = &quot;100%&quot;) Table 3.1: Price index for sale properties in Copenhagen City category 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 One-family houses 60.9 79.4 100 96.1 89.7 74.7 80.9 81.5 79.5 85.7 93.3 102 109 115 123 125 Owner-occupied flats, total 60.2 79.4 100 91.8 82.2 71.2 77.7 79.1 80.6 89.4 99.2 112 122 132 139 138 # Adjust housing prices price_index_2019 &lt;- filter(price_index, date == 2019) %&gt;% rename(index_2019 = index) res_units_oft &lt;- res_units_oft %&gt;% # Column with price index categories mutate(category = case_when( type == &quot;Single-family house&quot; ~ &quot;One-family houses&quot;, TRUE ~ &quot;Owner-occupied flats, total&quot;)) %&gt;% # Add price index by year and category left_join(price_index, by = c(&quot;category&quot; = &quot;category&quot;, &quot;BBR_year&quot; = &quot;date&quot;)) %&gt;% # Add price index in 2019 by category left_join(price_index_2019, by = c(&quot;category&quot; = &quot;category&quot;)) %&gt;% # Calculate prices 2019 mutate(price2019_kDKK = (KONTANT_KOEBESUM * index_2019 / index) / 1000) %&gt;% # Remove prices &lt; 10 kDKK filter(price2019_kDKK &gt;= 10) The housing price per square meter (\\(kDDK/m^2\\)) is calculated by dividing the 2019 adjusted prices by the dwelling size (BEBO_ARL). res_units_oft &lt;- res_units_oft %&gt;% # Price per m2 mutate(price2019_kDKK_m2 = price2019_kDKK / BEBO_ARL) The total number of residential units used for the analysis is 192570 (Table 3.2). # Table with Number of residential units res_units_oft %&gt;% # Summarize by type or residency and year group_by(type, BBR_year) %&gt;% summarise(n = n()) %&gt;% ungroup() %&gt;% # Arrange and add row with totals arrange(BBR_year, desc(n)) %&gt;% # Pivot pivot_wider(names_from = BBR_year, values_from = n) %&gt;% adorn_totals(&quot;row&quot;) %&gt;% kbl(caption = &quot;Number of residential dwellings in the free trade by year&quot;) %&gt;% kable_paper() %&gt;% row_spec(4, bold = TRUE) %&gt;% scroll_box(width = &quot;100%&quot;) Table 3.2: Number of residential dwellings in the free trade by year type 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 Multi-storey 12025 14080 13723 12195 7052 5056 13530 7128 8663 9589 11288 12733 11287 11910 11413 11759 Single-family house 663 669 547 561 462 429 770 527 885 653 692 694 711 703 660 716 Semi-detached house 267 288 280 355 256 203 303 471 451 481 514 525 1347 1254 1260 542 Total 12955 15037 14550 13111 7770 5688 14603 8126 9999 10723 12494 13952 13345 13867 13333 13017 The summary descriptive statistics of the housing prices are: # Table theme theme_gtsummary_compact() # Create variable labels of the variables to be printed in the table labelled::var_label(res_units_oft$price2019_kDKK) &lt;- &quot;Adjusted prices (kDKK)&quot; labelled::var_label(res_units_oft$BEBO_ARL) &lt;- &quot;Dwelling size (m2)&quot; labelled::var_label(res_units_oft$price2019_kDKK_m2) &lt;- &quot;Adjusted prices per square meter (kDKK/m2)&quot; # Summary table res_units_oft %&gt;% # Select variables of interest select(type, price2019_kDKK, BEBO_ARL, price2019_kDKK_m2) %&gt;% # Summary values tbl_summary(by = type, type = all_continuous() ~ &quot;continuous2&quot;, statistic = all_continuous() ~ c(&quot;{mean}&quot;, &quot;{median}&quot;, &quot;{p25} - {p75}&quot;, &quot;{min} - {max}&quot;), missing = &quot;no&quot;) %&gt;% add_overall() %&gt;% modify_spanning_header(c(&quot;stat_1&quot;, &quot;stat_2&quot;, &quot;stat_3&quot;) ~ &quot;**House type**&quot;) %&gt;% modify_footnote(update = everything() ~ NA) %&gt;% bold_labels() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #mwlefoodfi .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: small; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #mwlefoodfi .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mwlefoodfi .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #mwlefoodfi .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #mwlefoodfi .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mwlefoodfi .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mwlefoodfi .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #mwlefoodfi .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #mwlefoodfi .gt_column_spanner_outer:first-child { padding-left: 0; } #mwlefoodfi .gt_column_spanner_outer:last-child { padding-right: 0; } #mwlefoodfi .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #mwlefoodfi .gt_group_heading { padding: 1px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #mwlefoodfi .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #mwlefoodfi .gt_from_md > :first-child { margin-top: 0; } #mwlefoodfi .gt_from_md > :last-child { margin-bottom: 0; } #mwlefoodfi .gt_row { padding-top: 1px; padding-bottom: 1px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #mwlefoodfi .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #mwlefoodfi .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 1px; padding-bottom: 1px; padding-left: 5px; padding-right: 5px; } #mwlefoodfi .gt_first_summary_row { padding-top: 1px; padding-bottom: 1px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #mwlefoodfi .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 1px; padding-bottom: 1px; padding-left: 5px; padding-right: 5px; } #mwlefoodfi .gt_first_grand_summary_row { padding-top: 1px; padding-bottom: 1px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #mwlefoodfi .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #mwlefoodfi .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mwlefoodfi .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mwlefoodfi .gt_footnote { margin: 0px; font-size: 90%; padding: 1px; } #mwlefoodfi .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mwlefoodfi .gt_sourcenote { font-size: 90%; padding: 1px; } #mwlefoodfi .gt_left { text-align: left; } #mwlefoodfi .gt_center { text-align: center; } #mwlefoodfi .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #mwlefoodfi .gt_font_normal { font-weight: normal; } #mwlefoodfi .gt_font_bold { font-weight: bold; } #mwlefoodfi .gt_font_italic { font-style: italic; } #mwlefoodfi .gt_super { font-size: 65%; } #mwlefoodfi .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Characteristic Overall, N = 192,570 House type Multi-storey, N = 173,431 Semi-detached house, N = 8,797 Single-family house, N = 10,342 Adjusted prices (kDKK) Mean 47,732 52,013 9,910 8,099 Median 4,375 4,255 5,057 4,973 IQR 2,699 - 14,468 2,586 - 20,908 3,842 - 6,920 3,887 - 6,400 Range 11 - 1,778,677 11 - 1,778,677 30 - 261,346 25 - 291,062 Dwelling size (m2) Mean 89 84 131 137 Median 81 77 130 128 IQR 60 - 108 58 - 101 115 - 142 103 - 158 Range 10 - 733 11 - 655 12 - 402 10 - 733 Adjusted prices per square meter (kDKK/m2) Mean 667 730 83 101 Median 46 47 42 40 IQR 36 - 169 37 - 254 31 - 53 32 - 48 Range 0 - 37,056 0 - 37,056 0 - 15,876 0 - 17,500 "],["population-data.html", "Chapter 4 Population data", " Chapter 4 Population data Population data at parish level have been retrieved from Statistics Denmark using the R-package danstat. We have created two auxiliary function for reading the data. steps loops by year for getting small pieces of information from the DST API and then putting all together in a data frame. In this sense, we overcome the limitation of the number of rows we can retrieve from the API (i.e. if we call a large dataset we get the error: Error: API did not return text/csv). Then, rm_words is used in the cleaning process for simplifying the description of some variables we would like to use as columns names. # Loop by year for getting DST data steps &lt;- function(year){ var_values &lt;- list(id_region, id_ancestry, year) var_input &lt;- purrr::map2(.x = var_codes, .y = var_values, .f = ~list(code = .x, values = .y)) get_data(id_table, variables = var_input) } # Remove punctuation, lowercase, stem, stopwords, and collapse strings rm_words &lt;- function(x, stopwords) { x %&gt;% strsplit(&quot; &quot;, fixed = TRUE) %&gt;% lapply(tm::removePunctuation) %&gt;% lapply(tolower) %&gt;% lapply(SnowballC::wordStem) %&gt;% lapply(function(x) x[!x %in% stopwords]) %&gt;% vapply(function(x) paste(x , collapse = &quot;_&quot;), character(1)) } We have loaded the following tables: KMSTA001: Population 1. January by parish, ancestry and National Church id_table &lt;- &quot;KMSTA001&quot; var_pop &lt;- get_table_metadata(table_id = id_table, variables_only = TRUE) # Codes for var_input var_codes &lt;- c(&quot;SOGN&quot;, &quot;HERKOMST&quot;, &quot;Tid&quot;) # Values for var_input # Region: parishes of the study area (i.e. cph_parish) id_region &lt;- cph_parish$SOGNEKODE # Ancestry id_ancestry &lt;- NA # Quarters id_year &lt;- var_pop$values[[4]]$id # Select all years # Read data prsh_ances_dst &lt;- id_year %&gt;% future_map(steps) %&gt;% bind_rows() plan(&quot;default&quot;) # Clean data prsh_ances &lt;- prsh_ances_dst %&gt;% # Translate column names into English rename(parish = SOGN, ancestry = HERKOMST, date = TID, value = INDHOLD) %&gt;% # Get parish codes (first number of the string) mutate(prsh_id = stringr::str_extract(parish, &quot;[[:alnum:]]*&quot;)) %&gt;% # Remove the code from the string (prsh) mutate(parish = sub(&quot;[[:alnum:]]* &quot;, &quot;&quot;, parish)) %&gt;% # Get municipality (info inside the parenthesis) mutate(prsh_muni = stringr::str_extract(parish, &quot;(?&lt;=\\\\().*(?=\\\\))&quot;), prsh_muni = gsub(&quot; Municipality&quot;, &quot;&quot;, prsh_muni), # removes white space from start and end of string prsh_muni = stringr::str_trim(prsh_muni)) %&gt;% # Get parish name (outside parenthesis) mutate(prsh_name = stringr::str_extract(parish, &quot;(.*(?=\\\\())&quot;), prsh_name = stringr::str_trim(prsh_name)) %&gt;% # Remove duplicate info and order columns select(prsh_id, prsh_name, prsh_muni, date, ancestry, value) %&gt;% # Make shorter names in ancestry mutate(ancestry = case_when( ancestry == &quot;Persons of Danish origin&quot; ~ &quot;pop_dan&quot;, ancestry == &quot;Immigrants from western countries&quot; ~ &quot;pop_mi_wst&quot;, ancestry == &quot;Immigrants from non-western countries&quot; ~ &quot;pop_mi_nwst&quot;, ancestry == &quot;Descendants from western countries&quot; ~ &quot;pop_de_wst&quot;, ancestry == &quot;Descendants from non-western countries&quot; ~ &quot;pop_de_nwst&quot;), ancestry = factor(ancestry)) %&gt;% # Pivot (one row for peach parish and year) pivot_wider(names_from = ancestry, values_from = value) %&gt;% # Merge immigrants and their descendants (i.e. foreigners) mutate(pop_frgn_wst = pop_mi_wst + pop_de_wst, pop_frgn_nwst = pop_mi_nwst + pop_de_nwst) %&gt;% select(-c(pop_mi_wst, pop_de_wst, pop_mi_nwst, pop_de_nwst)) %&gt;% # Add column with total population mutate(pop_total = select(., starts_with(&quot;pop_&quot;)) %&gt;% rowSums()) KMSTA003: Summary vital statistics by parish and movements id_table &lt;- &quot;KMSTA003&quot; var_pop &lt;- get_table_metadata(table_id = id_table, variables_only = TRUE) # Codes for var_input var_codes &lt;- c(&quot;SOGN&quot;, &quot;KIRKEBEV&quot;, &quot;Tid&quot;) # Values for var_input # Region: all parish id_region &lt;- cph_parish$SOGNEKODE # Ancestry id_movements &lt;- NA # Quarters id_year &lt;- var_pop$values[[3]]$id # Select all years # Read data plan(multisession) prsh_stats_dst &lt;- id_year %&gt;% future_map(steps) %&gt;% bind_rows() plan(&quot;default&quot;) # Clean data prsh_stats &lt;- prsh_stats_dst %&gt;% # Translate column names into English rename(parish = SOGN, movements = KIRKEBEV, date = TID, value = INDHOLD) %&gt;% # Get parish codes (first number of the string) mutate(prsh_id = stringr::str_extract(parish, &quot;[[:alnum:]]*&quot;)) %&gt;% # Remove the code from the string (prsh) mutate(parish = sub(&quot;[[:alnum:]]* &quot;, &quot;&quot;, parish)) %&gt;% # Get municipality (info inside the parenthesis) mutate(prsh_muni = stringr::str_extract(parish, &quot;(?&lt;=\\\\().*(?=\\\\))&quot;), prsh_muni = gsub(&quot; Municipality&quot;, &quot;&quot;, prsh_muni), # removes white space from start and end of string prsh_muni = stringr::str_trim(prsh_muni)) %&gt;% # Get parish name (outside parenthesis) mutate(prsh_name = stringr::str_extract(parish, &quot;(.*(?=\\\\())&quot;), prsh_name = stringr::str_trim(prsh_name)) %&gt;% # remove duplicate info and order columns select(prsh_id, prsh_name, prsh_muni, date, movements, value) %&gt;% # Clean arguments in movements (remove punctuation, stop-words, stem, and collapse) mutate(movements = rm_words(movements, c(&quot;in&quot;, &quot;the&quot;, &quot;of&quot;))) %&gt;% # Pivot (one row for each parish and year) pivot_wider(names_from = movements, values_from = value) One we have the data we merge both dataset and add the spatial information (note that there are only summary statistics from 2015): # Merge both tables in one: prsh_pop &lt;- prsh_ances %&gt;% full_join(prsh_stats) %&gt;% # remove rows with no summary data (summary data only from 2015 to 2020) filter(date &gt;= 2015, date &lt;= 2020) # Add the spatial information: prsh_pop_sf &lt;- cph_parish %&gt;% rename(prsh_id = SOGNEKODE) %&gt;% select(prsh_id, prsh_area_km2) %&gt;% left_join(prsh_pop, by = c(&quot;prsh_id&quot;)) "],["corine-land-use.html", "Chapter 5 CORINE land use", " Chapter 5 CORINE land use Land use have been obtained from CORINE. We downloaded the shapefile from kortforsyningen and used the data from 2012 (CLC12_DK.shp). # Download CORINE to local repository (pks - dangeo) dangeo_get_data(ftp_folder = &quot;CORINE&quot;, zip_name = &quot;DK_CORINE_SHP_UTM32-WGS84.zip&quot;) # Create a table with the CORINE land use codes from the EEA corine_code_link &lt;- &quot;https://www.eea.europa.eu/data-and-maps/data/corine-land-cover-2000-clc2000-250-m-version-9-2007/corine-land-cover-2000-classes-and-rgb-color-codes/clc2000legend.csv/at_download/file&quot; corine_code &lt;- read_csv(corine_code_link) %&gt;% mutate_if(is.numeric, as.character) # Load shapefile dangeo_set_param() # Get local directory corine_link &lt;- paste(loc_dir, &quot;DK_CORINE_SHP_UTM32-WGS84&quot;, &quot;CLC12_DK.shp&quot;, sep = &quot;/&quot;) dk_corine &lt;- read_sf(corine_link) %&gt;% # Drop z dimension st_zm() %&gt;% # Transform coordinates st_transform(crs = &quot;EPSG:25832&quot;) %&gt;% # Add code description left_join(corine_code, by = c(&quot;CODE_12&quot; = &quot;CLC_CODE&quot;)) # Select study area cph_corine &lt;- st_intersection(dk_corine, study_area) %&gt;% select(CODE_12, LABEL1, LABEL2, LABEL3 , RGB) %&gt;% janitor::clean_names() %&gt;% separate(rgb, c(&quot;red&quot;, &quot;green&quot;, &quot;blue&quot;), sep = &quot;-&quot;) %&gt;% mutate(code_12 = as.numeric(code_12), hex_col = grDevices::rgb(red, green, blue, max = 255), hex_col = fct_reorder(hex_col, code_12), label3 = fct_reorder(label3, code_12)) %&gt;% st_sf() # Plot ggplot() + geom_sf(data = cph_corine, aes(fill = label3), color = &quot;grey50&quot;, size = 0.05) + #geom_sf(data = res_units, size = 0.02, shape = 16) + scale_fill_manual(name = &quot;Land use&quot;, values = levels(cph_corine$hex_col), drop = TRUE) + my_theme_map() + labs(x = &quot;&quot;, y = &quot;&quot;) + annotation_scale(location = &quot;br&quot;, text_cex = 1) + annotation_north_arrow(location = &quot;br&quot;, pad_x = unit(1.50, &quot;cm&quot;), pad_y = unit(0.65, &quot;cm&quot;), which_north = &quot;true&quot;, height = unit(0.5, &quot;cm&quot;), width = unit(0.5, &quot;cm&quot;), style = north_arrow_orienteering(text_col = &quot;white&quot;, text_size = 1)) Figure 5.1: Land use (CORINE) "],["railway-transport-network.html", "Chapter 6 Railway transport network", " Chapter 6 Railway transport network Downloaded from kortforsyningen (i.e. Inspire_railway-transport-network). dangeo_get_data( ftp_folder = &quot;grundlaeggende_landkortdata/inspire_railway-transport-network&quot;, zip_name = &quot;DK_RailwayTransportNetwork_GML_UTM32-EUREF89.zip&quot;) "],["geodanmark.html", "Chapter 7 GeoDanmark", " Chapter 7 GeoDanmark Downloaded from kortforsyningen (i.e. grundlaeggende_landkortdata). dangeo_get_data(ftp_folder = &quot;grundlaeggende_landkortdata/fot/SHAPE&quot;, zip_name = &quot;DK_SHAPE_UTM32-EUREF89.zip&quot;) "],["Population.html", "Chapter 8 Population density 8.1 Choropleth by ancestry 8.2 Disaggregating population data 8.3 Population density WorldPop", " Chapter 8 Population density BBR data represent the situation at the begining of the given year. Therefore, when we link the BBR data with the population data, which also represent the situation at the first day of the year, we use the population of the same year (e.g. BBR data from 2019 and population data from 2019). 8.1 Choropleth by ancestry Plot population density at the last day of 2019 (first of 2010) by parish and ancestry. col &lt;- brewer.pal(9, &quot;YlGnBu&quot;) pal &lt;- colorRampPalette(col) my_pallette &lt;- pal(10) pop_dens_choropleth &lt;- prsh_pop_sf %&gt;% select(prsh_id, prsh_name, prsh_area_km2, date, pop_total, pop_dan, pop_frgn_wst, pop_frgn_nwst) %&gt;% filter(date == 2019) %&gt;% # Calulate population density (pop/area) mutate(across(starts_with(&quot;pop_&quot;), ~ . / (1000 * prsh_area_km2))) %&gt;% rename_with(~paste(.x, &quot;km2&quot;, sep = &quot;_&quot;), starts_with(&quot;pop&quot;)) %&gt;% as_tibble() %&gt;% pivot_longer(starts_with(&quot;pop_&quot;)) %&gt;% st_as_sf() %&gt;% mutate(name = factor(name, levels = c(&quot;pop_total_km2&quot;, &quot;pop_dan_km2&quot;, &quot;pop_frgn_wst_km2&quot;, &quot;pop_frgn_nwst_km2&quot;), labels = c(&quot;Total&quot;, &quot;Danish origin&quot;, &quot;Immigrants and their descendants from western countries&quot;, &quot;Immigrants and their descendants from non-western countries&quot;))) brks_c &lt;- c(min(pop_dens_choropleth$value), 1, 2, 4, 8, 12, 16, 20, 25, 30, ceiling(max(pop_dens_choropleth$value))) pop_dens_choropleth %&gt;% ggplot() + geom_sf(aes(fill = cut(value, breaks = brks_c, include.lowest = T)), color = &quot;grey50&quot;, size = 0.05) + scale_fill_manual(name = TeX(&quot;$\\\\overset{\\\\textbf{Population}}{(x1000/km^2)}$&quot;), values = my_pallette, drop = FALSE, guide = guide_legend(reverse=TRUE)) + my_theme_map() + theme(plot.title = element_text(size = 12, colour = &quot;darkblue&quot;, face = &quot;bold&quot;), strip.text = element_text(size = 9, color = &quot;black&quot;, face = &quot;italic&quot;)) + labs(x = &quot;&quot;, y = &quot;&quot;) + facet_wrap( ~ name) Figure 8.1: Population density at the first day of 2019 by parishes (choropleth) 8.2 Disaggregating population data We disaggregate the population data at Parish level to grid cells of 100m x 100m using residential buildings as ancillary data. The procedure is as follow: We calculate the occupancy rate (OR) for the residential units of each parish (j): \\[OR_{j} = \\frac{pop_{j}}{N_{j}}\\] We make grid cells of 100m x 100m over the study area We select only the grids with residential units Detect to what parish (j) belong each grid (i). (Note that one grids may be in more that one parish) Calculate the number of dwellings per grid and parish (\\(N_{ij}\\)) Estimate the population in each grid (i) base the occupancy rate by parish (j): \\[pop_{gi} = \\sum_{j = 1}^{n}(OR_{j} \\cdot N_{ij})\\] Population density: \\[PD_{i} = \\frac{pop_{i}}{A_{i}}\\] Therefore we create the following function: #&#39; Calculate the population density in the grids created by f_grids #&#39; @param .pop POLYGONS with the population data (i.e. prsh_pop_sf) #&#39; @param .parish POLYGONS where the number of units will be calculated #&#39; @param .res_points POINTS with the residential units (e.g. res_units) #&#39; @param .grids Grid cells generated by f_grids #&#39; @param .year Year of the analysis f_pd_grids &lt;- function(.pop, .parish, .res_points, .grids, .year) { # Population at the last day of the year (.year) pop_year &lt;- .pop %&gt;% # Select population data at the first day of the quarter select(prsh_id, prsh_name, prsh_area_km2, date, pop_total, pop_dan, pop_frgn_wst, pop_frgn_nwst) %&gt;% # select the data at the end of the year (first dat of the next year) filter(date == (.year)) # BBR of the selected year (represent the last day of the year) BBR_year &lt;- filter(.res_points, BBR_year == .year) # Calculate occupancy rate (&quot;OR&quot;) of the residential units in each parish in a year OR &lt;- pop_year %&gt;% # number of units per parish mutate(n_units = st_intersects(., BBR_year, dist = 10) %&gt;% map(., ~length(.)) %&gt;% unlist()) %&gt;% # mean population per unit in each parish mutate(across(starts_with(&quot;pop&quot;), ~ . / n_units)) %&gt;% rename_with(~paste(.x, &quot;or&quot;, sep = &quot;_&quot;), starts_with(&quot;pop&quot;)) %&gt;% # output as table as_tibble() %&gt;% select(-n_units, -geometry) # Get only the grids with residential units on them gru &lt;- .grids %&gt;% # Number of residential units per grid mutate(n_units = st_intersects(., BBR_year , dist = 10) %&gt;% map(., ~length(.)) %&gt;% unlist()) %&gt;% # Get grids with residential buildings filter(n_units &gt; 0) %&gt;% # Detect to what parish belong the grid st_intersection(., .parish ) %&gt;% # Remove parish area select(-prsh_area_km2, -SOGNENAVN) %&gt;% # convert to table as_tibble() # Population density by grids gru %&gt;% # Merge OR per parish left_join(OR, by = c(&quot;SOGNEKODE&quot; = &quot;prsh_id&quot;)) %&gt;% st_sf() %&gt;% # recalculate population by grid mutate(across(starts_with(&quot;pop&quot;), ~ . * n_units)) %&gt;% rename_with(~gsub(&quot;_or&quot;, &quot;&quot;, .), .col = starts_with(&quot;pop&quot;)) %&gt;% # sum population of each parish of the grid group_by(grid_ID) %&gt;% summarise(pop_total = sum(pop_total), pop_dan = sum(pop_dan), pop_frgn_wst = sum(pop_frgn_wst), pop_frgn_nwst = sum(pop_frgn_nwst), n_units = sum(n_units)) %&gt;% ungroup() %&gt;% # Area of the grid mutate(area_km2 = as.numeric(units::set_units(st_area(.), km^2))) %&gt;% # Population density (pop/area) mutate(across(starts_with(&quot;pop_&quot;), ~ . / (1000 * area_km2))) %&gt;% rename_with(~paste(.x, &quot;km2&quot;, sep = &quot;_&quot;), starts_with(&quot;pop&quot;)) %&gt;% # Pivot longer as_tibble() %&gt;% pivot_longer(starts_with(&quot;pop_&quot;)) %&gt;% st_as_sf() %&gt;% # Remove polygons with 0 population filter(value &gt; 0) } Population in 2019 (at the first dat of the year) by grid cells of 100m x 100m and ancestry. pop_2019_g100m &lt;- f_pd_grids(.pop = prsh_pop_sf, .parish = cph_parish, .res_points = res_units, .grids = grids100m, .year = 2019) brks &lt;- c(min(pop_2019_g100m$value), 1, 2, 4, 8, 12, 16, 20, 25, 30, ceiling(max(pop_2019_g100m$value))) pop_2019_g100m %&gt;% mutate(name = factor(name, levels = c(&quot;pop_total_km2&quot;, &quot;pop_dan_km2&quot;, &quot;pop_frgn_wst_km2&quot;, &quot;pop_frgn_nwst_km2&quot;), labels = c(&quot;Total&quot;, &quot;Danish origin&quot;, &quot;Immigrants and their descendants from western countries&quot;, &quot;Immigrants and their descendants from non-western countries&quot;))) %&gt;% ggplot() + geom_sf(data = cph_parish, fill = &quot;grey&quot;, color = &quot;grey50&quot;, size = 0.05) + geom_sf(aes(fill = cut(value, breaks = brks, include.lowest = T)), color = NA) + scale_fill_manual(name = TeX(&quot;$\\\\overset{\\\\textbf{Population}}{(x1000/km^2)}$&quot;), values = my_pallette, drop = FALSE, guide = guide_legend(reverse = TRUE)) + my_theme_map() + theme(plot.title = element_text(size = 12, colour = &quot;darkblue&quot;, face = &quot;bold&quot;), strip.text = element_text(size = 9, color = &quot;black&quot;, face = &quot;italic&quot;)) + labs(x = &quot;&quot;, y = &quot;&quot;) + facet_wrap( ~ name) Figure 8.2: Population density at the first day of 2019 by grid cells of 100m x 100m 8.3 Population density WorldPop We can compare our results with the WorldPop total population estimation per grid-cell of 3 arc (approx. gri cells of 100m x 100m): dnk_ppp_2019_link &lt;- &quot;https://data.worldpop.org/GIS/Population/Global_2000_2020/2019/DNK/dnk_ppp_2019.tif&quot; # Download data into the local repository (i.e. loc_dir) download.file(url = dnk_ppp_2019_link, destfile = paste(loc_dir, &quot;dnk_ppp_2019.tif&quot;, sep = &quot;/&quot;), method = &quot;curl&quot;) # Load file dnk_ppp_2019 &lt;- read_stars(.x = paste(loc_dir, &quot;dnk_ppp_2019.tif&quot;, sep = &quot;/&quot;), proxy = TRUE) # Crop study area bbox &lt;- study_area %&gt;% st_transform(crs = st_crs(dnk_ppp_2019)) cph_ppp_2019 &lt;- st_crop(dnk_ppp_2019, bbox) %&gt;% st_transform(crs = &quot;EPSG:25832&quot;) # Plot col &lt;- brewer.pal(9, &quot;YlGnBu&quot;) pal &lt;- colorRampPalette(col) my_pallette &lt;- pal(10) brks &lt;- c(min(cph_ppp_2019$dnk_ppp_2019.tif, na.rm = TRUE), 1, 2, 4, 8, 12, 16, 20, 25, 30, max(cph_ppp_2019$dnk_ppp_2019.tif, na.rm = TRUE)) cph_ppp_2019 &lt;- cph_ppp_2019 %&gt;% mutate( pop_cuts = cut(dnk_ppp_2019.tif, breaks = brks, include.lowest = T)) ggplot() + geom_sf(data = cph_parish, fill = &quot;grey&quot;, color = &quot;grey50&quot;, size = 0.05) + geom_stars(data = cph_ppp_2019, aes(fill = pop_cuts)) + scale_fill_manual(name = TeX(&quot;$\\\\overset{\\\\textbf{Population}}{(x1000/km^2)}$&quot;), values = my_pallette, drop = FALSE, guide = guide_legend(reverse=TRUE)) + labs(title = &quot;Estimated total number of people per grid-cell of 3 arc&quot;, caption = &quot;Source: WorlpPop (https://data.worldpop.org)&quot;) + my_theme_map() Figure 8.3: WorldPop total population density estimations in 2019 "],["residential-units-saled-as-free-scale.html", "Chapter 9 Residential units saled as free scale 9.1 Residential units by floor level", " Chapter 9 Residential units saled as free scale We focused our study in residential dwellings on the ordinary free trade (Table 3.2). NOTES: There are large differences in the number of residential units between years, why?? Study only one year for the moment (e.g. 2019)?? Housing prices in different years -&gt; adjust to 2019 prices (what index; Table 3.1)? KONTANT_KOEBESUM = cash purchase price? Analyse it?? What about KOEBESUM_BELOEB = The purchase price agreed upon the sale of the property??? KONTANT_KOEBESUM = 0 or (&lt; 100000 DKK)? SKOEDE_DATO = The date on which the deed was signed -&gt; use as sale date?? Should we use this date (i.e. for the price index)?  What about housing prices = 0? Dwelling Area &lt;= 0? res_units_oft %&gt;% ggplot(aes(sample = log10(price2019_kDKK), colour = factor(BBR_year))) + geom_qq() + #geom_qq_line() + facet_grid(~type) + theme_bw() 9.1 Residential units by floor level KL - basement ST - ground floor 1 - 1st floor 2 - 2nd floor 3 - 3rd floor 4 - 4th floor 5 or more = etc. res_units_oft %&gt;% group_by(floor_level, type) %&gt;% summarise(n = n()) %&gt;% ungroup() %&gt;% # in percentage [%] mutate(perc = 100 * n / sum(n)) %&gt;% # Reorder type levels for plotting multi-storey first mutate(type = factor(type)) %&gt;% ggplot() + geom_bar(aes(y = floor_level, x = perc, fill = type), stat = &quot;identity&quot;) + labs(y = &quot;&quot;, x = &quot;Percentage [%]&quot;) + theme_bw() + theme(legend.position = &quot;bottom&quot;, legend.title = element_blank()) + guides(fill = guide_legend(ncol = 2)) + scale_x_continuous(labels = scales::comma) + scale_fill_manual(values = c(&quot;#0072B2&quot;, &quot;#D55E00&quot;, &quot;#CC79A7&quot;)) Figure 9.1: Residential units distribution by floor level "],["references.html", "References", " References Chen, Jie, and Qianjin Hao. 2008. The impacts of distance to CBD on housing prices in Shanghai: a hedonic analysis. Journal of Chinese Economic and Business Studies 6 (3): 291302. https://doi.org/10.1080/14765280802283584. Giraud, Timothée, and Hadrien Commenges. 2020. potential: Implementation of the Potential Model. R Package Version 0.1.0. https://cran.r-project.org/package=potential. Gultekin, Bahadir, and Etsuo Yamamura. 2006. Potential and Network Analysis Application of Estimating Housing Prices in Northern District of Sapporo. Studies in Regional Science 35 (4): 1097107. https://doi.org/10.2457/srs.35.1097. Valtersdorf Møller, Katrine. 2020. The influence of traffic noise on house prices. Aalborg University. https://projekter.aau.dk/projekter/files/334368384/Thesis{\\_}without{\\_}appendix.pdf. Weber, Christiane, and Jacky Hirsch. 2000. Potential model application and planning issues. Cybergeo, no. 1995 (March). https://doi.org/10.4000/cybergeo.889. "]]
